import streamlit as st
import pandas as pd
import json
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import re
import time
import random
import hashlib
import uuid
from pathlib import Path
from collections import defaultdict

# Course Descriptions with 4 CLOs each
COURSE_DESCRIPTIONS = {
    '282711': {
        'name': '‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',
        'description': '‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏® ‡∏û‡∏•‡∏ß‡∏±‡∏ï‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÇ‡∏•‡∏Å ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ï‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏ä‡∏µ‡∏ß‡∏†‡∏≤‡∏û',
        'clo': {
            'CLO1': '‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏û‡∏•‡∏ß‡∏±‡∏ï‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÇ‡∏•‡∏Å',
            'CLO2': '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ï‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏ä‡∏µ‡∏ß‡∏†‡∏≤‡∏û',
            'CLO3': '‡∏≠‡∏†‡∏¥‡∏õ‡∏£‡∏≤‡∏¢‡∏Å‡∏£‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡πà‡∏ß‡∏°‡∏°‡∏∑‡∏≠‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡∏≤‡∏ô‡∏≤‡∏ä‡∏≤‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',
            'CLO4': '‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏≤‡∏á‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®'
        },
        'keywords': {
            'CLO1': ['‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢', '‡∏û‡∏•‡∏ß‡∏±‡∏ï', '‡∏£‡∏∞‡∏ö‡∏ö‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®', '‡πÇ‡∏•‡∏Å', '‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®', '‡πÄ‡∏£‡∏∑‡∏≠‡∏ô‡∏Å‡∏£‡∏∞‡∏à‡∏Å', 'factors', 'dynamics', 'climate system'],
            'CLO2': ['‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö', '‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏ä‡∏µ‡∏ß‡∏†‡∏≤‡∏û', 'ecosystem', 'biodiversity', 'impact', 'effects'],
            'CLO3': ['‡∏Å‡∏£‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡πà‡∏ß‡∏°‡∏°‡∏∑‡∏≠', '‡∏ô‡∏≤‡∏ô‡∏≤‡∏ä‡∏≤‡∏ï‡∏¥', '‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á', 'international', 'framework', 'model', 'UNFCCC'],
            'CLO4': ['‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ', '‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠', '‡∏™‡∏±‡∏á‡∏Ñ‡∏°', 'technology', 'tools', 'social', 'application']
        },
        'plo_mapping': ['PLO1', 'PLO2'],
        'ylo_mapping': ['YLO1.1']
    },
    '282712': {
        'name': '‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô',
        'description': '‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥ ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ï‡πà‡∏≠‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ô‡πâ‡∏≥‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏´‡∏≤‡∏ô‡πâ‡∏≥‡∏ó‡∏µ‡πà‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®‡∏†‡∏π‡∏°‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥',
        'clo': {
            'CLO1': '‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',
            'CLO2': '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ô‡πâ‡∏≥‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏´‡∏≤‡∏ô‡πâ‡∏≥‡∏ó‡∏µ‡πà‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏•‡∏∏‡πà‡∏°‡∏ô‡πâ‡∏≥',
            'CLO3': '‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏†‡∏π‡∏°‡∏¥‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥',
            'CLO4': '‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ô‡πâ‡∏≥‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô'
        },
        'keywords': {
            'CLO1': ['‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥', '‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå', '‡∏õ‡∏±‡∏ç‡∏´‡∏≤', '‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á', 'water resources', 'situation', 'problems'],
            'CLO2': ['‡πÉ‡∏ä‡πâ‡∏ô‡πâ‡∏≥', '‡∏à‡∏±‡∏î‡∏´‡∏≤‡∏ô‡πâ‡∏≥', '‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô', '‡∏•‡∏∏‡πà‡∏°‡∏ô‡πâ‡∏≥', 'sustainable', 'watershed', 'water supply'],
            'CLO3': ['GIS', '‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ', '‡∏†‡∏π‡∏°‡∏¥‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®', '‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£', 'technology', 'geographic information'],
            'CLO4': ['‡πÅ‡∏ú‡∏ô', '‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£', '‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°', '‡∏ä‡∏∏‡∏°‡∏ä‡∏ô', 'plan', 'participation', 'community']
        },
        'plo_mapping': ['PLO1', 'PLO2'],
        'ylo_mapping': ['YLO1.1', 'YLO1.2']
    },
    '282713': {
        'name': '‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ó‡∏≤‡∏á‡∏ö‡∏Å',
        'description': '‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ó‡∏≤‡∏á‡∏ö‡∏Å ‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏£‡∏±‡∏Å‡∏©‡πå‡πÅ‡∏•‡∏∞‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ó‡∏≤‡∏á‡∏ö‡∏Å ‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡πà‡∏≤‡πÑ‡∏°‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏ä‡∏µ‡∏ß‡∏†‡∏≤‡∏û',
        'clo': {
            'CLO1': '‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ó‡∏≤‡∏á‡∏ö‡∏Å',
            'CLO2': '‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ï‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ó‡∏≤‡∏á‡∏ö‡∏Å',
            'CLO3': '‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏≠‡∏ô‡∏∏‡∏£‡∏±‡∏Å‡∏©‡πå‡πÅ‡∏•‡∏∞‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ó‡∏≤‡∏á‡∏ö‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô',
            'CLO4': '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏î‡∏¥‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡πà‡∏≤‡πÑ‡∏°‡πâ'
        },
        'keywords': {
            'CLO1': ['‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®', '‡∏ó‡∏≤‡∏á‡∏ö‡∏Å', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå', '‡∏õ‡∏±‡∏ç‡∏´‡∏≤', 'terrestrial', 'ecosystem', 'relationship'],
            'CLO2': ['‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô', '‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö', '‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á', 'assess', 'impact', 'climate change'],
            'CLO3': ['‡∏≠‡∏ô‡∏∏‡∏£‡∏±‡∏Å‡∏©‡πå', '‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π', '‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô', 'conservation', 'restoration', 'sustainable'],
            'CLO4': ['‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ', '‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏î‡∏¥‡∏ô', '‡∏õ‡πà‡∏≤‡πÑ‡∏°‡πâ', 'technology', 'soil', 'forest']
        },
        'plo_mapping': ['PLO1', 'PLO2'],
        'ylo_mapping': ['YLO1.1']
    },
    '282714': {
        'name': '‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ',
        'description': '‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡∏ö‡∏Ñ‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏á‡∏≤‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ‡∏Å‡∏≤‡∏£‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡∏ß‡∏£‡∏£‡∏ì‡∏Å‡∏£‡∏£‡∏° ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥',
        'clo': {
            'CLO1': '‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏£‡πà‡∏≤‡∏á‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°',
            'CLO2': '‡∏™‡∏∑‡∏ö‡∏Ñ‡πâ‡∏ô ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡∏£‡∏£‡∏ì‡∏Å‡∏£‡∏£‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö',
            'CLO3': '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏ß‡∏¥‡∏à‡∏±‡∏¢',
            'CLO4': '‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏à‡∏£‡∏£‡∏¢‡∏≤‡∏ö‡∏£‡∏£‡∏ì‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ AI ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ß‡∏¥‡∏à‡∏±‡∏¢'
        },
        'keywords': {
            'CLO1': ['‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö', '‡πÇ‡∏Ñ‡∏£‡∏á‡∏£‡πà‡∏≤‡∏á', '‡∏ß‡∏¥‡∏à‡∏±‡∏¢', 'design', 'research', 'proposal'],
            'CLO2': ['‡∏™‡∏∑‡∏ö‡∏Ñ‡πâ‡∏ô', '‡∏ß‡∏£‡∏£‡∏ì‡∏Å‡∏£‡∏£‡∏°', '‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô', 'literature', 'review', 'systematic'],
            'CLO3': ['‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ', '‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥', '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå', 'methodology', 'statistics', 'analysis'],
            'CLO4': ['‡∏à‡∏£‡∏£‡∏¢‡∏≤‡∏ö‡∏£‡∏£‡∏ì', 'AI', '‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏°', 'ethics', 'artificial intelligence']
        },
        'plo_mapping': ['PLO2', 'PLO3'],
        'ylo_mapping': ['YLO1.2', 'YLO1.3']
    },
    '282715': {
        'name': '‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',
        'description': '‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏® ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏™‡∏∞‡∏≠‡∏≤‡∏î ‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏≤‡∏£‡πå‡∏ö‡∏≠‡∏ô ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏õ‡πà‡∏≤‡πÑ‡∏°‡πâ',
        'clo': {
            'CLO1': '‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',
            'CLO2': '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏Ç‡∏≠‡∏á‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏î‡πâ‡∏≤‡∏ô‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏™‡∏∞‡∏≠‡∏≤‡∏î ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ô‡πâ‡∏≥ ‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',
            'CLO3': '‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡πÑ‡∏Å‡∏ó‡∏≤‡∏á‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',
            'CLO4': '‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®'
        },
        'keywords': {
            'CLO1': ['‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ', '‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡∏±‡∏î', '‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°', 'technology', 'monitoring', 'measurement'],
            'CLO2': ['‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏™‡∏∞‡∏≠‡∏≤‡∏î', '‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß', 'clean energy', 'green building', 'adaptation'],
            'CLO3': ['‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢', '‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå', '‡∏Å‡∏•‡πÑ‡∏Å', 'policy', 'economics', 'mechanism'],
            'CLO4': ['‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£', '‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°', '‡∏™‡∏±‡∏á‡∏Ñ‡∏°', 'communication', 'participation', 'society']
        },
        'plo_mapping': ['PLO1', 'PLO2'],
        'ylo_mapping': ['YLO1.1', 'YLO2.1']
    }
}

# Enhanced Year Learning Outcomes (YLO) Configuration
YLO_STRUCTURE = {
    'YLO1.1': {
        'description': '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏° ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏® ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥ ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ó‡∏≤‡∏á‡∏ö‡∏Å ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Å‡∏±‡∏ö‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏á‡∏Ñ‡∏°',
        'detailed_description': '‡∏ô‡∏¥‡∏™‡∏¥‡∏ï‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏ö‡∏ö‡∏≠‡∏á‡∏Ñ‡πå‡∏£‡∏ß‡∏° ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏® ‡∏≠‡∏∏‡∏ó‡∏Å‡∏°‡∏ì‡∏ë‡∏• ‡∏ò‡∏£‡∏ì‡∏µ‡∏°‡∏ì‡∏ë‡∏• ‡πÅ‡∏•‡∏∞‡∏ä‡∏µ‡∏ß‡∏°‡∏ì‡∏ë‡∏• ‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏ï‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ',
        'plo_mapping': ['PLO1', 'PLO2'],
        'level': 'Year 1',
        'cognitive_level': 'Understanding',
        'assessment_methods': ['‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô', '‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠', '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°']
    },
    'YLO1.2': {
        'description': '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢ ‡πÇ‡∏î‡∏¢‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô',
        'detailed_description': '‡∏ô‡∏¥‡∏™‡∏¥‡∏ï‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢ ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡∏ß‡∏£‡∏£‡∏ì‡∏Å‡∏£‡∏£‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡πÅ‡∏•‡∏∞‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢',
        'plo_mapping': ['PLO1', 'PLO2'],
        'level': 'Year 1',
        'cognitive_level': 'Applying',
        'assessment_methods': ['‡πÇ‡∏Ñ‡∏£‡∏á‡∏£‡πà‡∏≤‡∏á‡∏ß‡∏¥‡∏à‡∏±‡∏¢', '‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠', '‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô']
    },
    'YLO1.3': {
        'description': '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡∏ö‡∏Ñ‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏™‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©',
        'detailed_description': '‡∏ô‡∏¥‡∏™‡∏¥‡∏ï‡∏°‡∏µ‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ ‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡∏ö‡∏Ñ‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏£‡∏∞‡∏ö‡∏ö ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏Å‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏ç‡∏≤‡∏ì',
        'plo_mapping': ['PLO2', 'PLO3'],
        'level': 'Year 1',
        'cognitive_level': 'Applying',
        'assessment_methods': ['‡∏Å‡∏≤‡∏£‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡∏ß‡∏£‡∏£‡∏ì‡∏Å‡∏£‡∏£‡∏°', '‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°', '‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠']
    },
    'YLO1.4': {
        'description': '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏•‡∏∞‡∏≠‡∏†‡∏¥‡∏õ‡∏£‡∏≤‡∏¢‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÑ‡∏î‡πâ',
        'detailed_description': '‡∏ô‡∏¥‡∏™‡∏¥‡∏ï‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏°‡∏µ‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏†‡∏¥‡∏õ‡∏£‡∏≤‡∏¢‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ä‡∏≤‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏ô‡∏≤‡∏ô‡∏≤‡∏ä‡∏≤‡∏ï‡∏¥',
        'plo_mapping': ['PLO3'],
        'level': 'Year 1',
        'cognitive_level': 'Evaluating',
        'assessment_methods': ['‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡∏õ‡∏≤‡∏Å‡πÄ‡∏õ‡∏•‡πà‡∏≤', '‡∏Å‡∏≤‡∏£‡∏≠‡∏†‡∏¥‡∏õ‡∏£‡∏≤‡∏¢‡∏Å‡∏•‡∏∏‡πà‡∏°', '‡∏™‡∏±‡∏°‡∏°‡∏ô‡∏≤']
    },
    'YLO2.1': {
        'description': '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô',
        'detailed_description': '‡∏ô‡∏¥‡∏™‡∏¥‡∏ï‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á ‡πÄ‡∏ä‡πà‡∏ô GIS, Remote Sensing, AI, ‡πÅ‡∏•‡∏∞ IoT ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÇ‡∏ã‡∏•‡∏π‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô',
        'plo_mapping': ['PLO1', 'PLO2'],
        'level': 'Year 2',
        'cognitive_level': 'Creating',
        'assessment_methods': ['‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢', '‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡πÇ‡∏ã‡∏•‡∏π‡∏ä‡∏±‡∏ô', '‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö']
    },
    'YLO2.2': {
        'description': '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏´‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏• ‡πÅ‡∏•‡∏∞‡∏≠‡∏†‡∏¥‡∏õ‡∏£‡∏≤‡∏¢‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏® ‡πÇ‡∏î‡∏¢‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏°‡∏à‡∏£‡∏£‡∏¢‡∏≤‡∏ö‡∏£‡∏£‡∏ì‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£',
        'detailed_description': '‡∏ô‡∏¥‡∏™‡∏¥‡∏ï‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏≤‡∏Å‡∏• ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏†‡∏¥‡∏õ‡∏£‡∏≤‡∏¢‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô',
        'plo_mapping': ['PLO2'],
        'level': 'Year 2',
        'cognitive_level': 'Evaluating',
        'assessment_methods': ['‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏ô‡∏¥‡∏û‡∏ô‡∏ò‡πå', '‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°', '‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£']
    },
    'YLO2.3': {
        'description': '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£ ‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≠‡∏î‡∏≠‡∏á‡∏Ñ‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏ô‡∏¥‡∏û‡∏ô‡∏ò‡πå/‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏Ñ‡πâ‡∏ô‡∏Ñ‡∏ß‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏ô‡πÄ‡∏≠‡∏á ‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡πÉ‡∏ô‡∏ß‡∏≤‡∏£‡∏™‡∏≤‡∏£ ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏°‡∏à‡∏£‡∏£‡∏¢‡∏≤‡∏ö‡∏£‡∏£‡∏ì‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°',
        'detailed_description': '‡∏ô‡∏¥‡∏™‡∏¥‡∏ï‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ú‡πà‡∏≤‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á ‡πÅ‡∏•‡∏∞‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏π‡πà‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏ß‡πâ‡∏≤‡∏á',
        'plo_mapping': ['PLO3'],
        'level': 'Year 2',
        'cognitive_level': 'Creating',
        'assessment_methods': ['‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏ô‡∏¥‡∏û‡∏ô‡∏ò‡πå', '‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£', '‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡∏ï‡πà‡∏≠‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞']
    }
}

# Cognitive Development Framework
COGNITIVE_FRAMEWORK = {
    'Understanding': {
        'description': '‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô',
        'examples': ['‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢', '‡∏™‡∏£‡∏∏‡∏õ', '‡πÅ‡∏õ‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢', '‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á']
    },
    'Applying': {
        'description': '‡∏ô‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏´‡∏°‡πà',
        'examples': ['‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ', '‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤', '‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£', '‡∏™‡∏≤‡∏ò‡∏¥‡∏ï']
    },
    'Evaluating': {
        'description': '‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•',
        'examples': ['‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå', '‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö', '‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô', '‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤']
    },
    'Creating': {
        'description': '‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå‡∏™‡∏¥‡πà‡∏á‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö',
        'examples': ['‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö', '‡∏™‡∏£‡πâ‡∏≤‡∏á', '‡∏û‡∏±‡∏í‡∏ô‡∏≤', '‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°']
    }
}

# Enhanced PLO Configuration with comprehensive descriptions
ENHANCED_PLOS = {
    'PLO1': {
        'title': '‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°',
        'description': '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏≤‡∏á‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏® ‡πÇ‡∏î‡∏¢‡∏¢‡∏∂‡∏î‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô',
        'detailed_description': '‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®‡∏†‡∏π‡∏°‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå (GIS), ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡∏£‡∏∞‡∏¢‡∏∞‡πÑ‡∏Å‡∏• (Remote Sensing), ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏° ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡πÑ‡∏î‡πâ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏° ‡∏ï‡∏•‡∏≠‡∏î‡∏à‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÇ‡∏ã‡∏•‡∏π‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô',
        'weight': 35,
        'color': '#FF6B6B',
        'focus_areas': ['‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°', '‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°', '‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô', '‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß']
    },
    'PLO2': {
        'title': '‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£',
        'description': '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏≠‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',
        'detailed_description': '‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏´‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤ ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏° ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡πÅ‡∏•‡∏∞‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û',
        'weight': 35,
        'color': '#4ECDC4',
        'focus_areas': ['‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏¥‡∏à‡∏±‡∏¢', '‡∏Å‡∏≤‡∏£‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏°‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå', '‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•', '‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢']
    },
    'PLO3': {
        'title': '‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≠‡∏î',
        'description': '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£ ‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≠‡∏î ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û',
        'detailed_description': '‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ ‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢ ‡∏ä‡∏∏‡∏°‡∏ä‡∏ô ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏™‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏±‡∏î‡∏ó‡∏≥‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡∏¥‡∏à‡∏±‡∏¢ ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠ ‡πÅ‡∏•‡∏∞‡∏™‡∏∑‡πà‡∏≠‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏• ‡∏ï‡∏•‡∏≠‡∏î‡∏à‡∏ô‡∏°‡∏µ‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô',
        'weight': 30,
        'color': '#45B7D1',
        'focus_areas': ['‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå', '‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠', '‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£', '‡∏™‡∏∑‡πà‡∏≠‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•']
    }
}

# Program Overview and Context
PROGRAM_OVERVIEW = {
    'program_name': '‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡∏°‡∏´‡∏≤‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',
    'program_philosophy': '‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ô‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡∏≤‡∏°‡∏à‡∏£‡∏£‡∏¢‡∏≤‡∏ö‡∏£‡∏£‡∏ì‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏® ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô‡∏Ç‡∏≠‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°',
    'program_objectives': [
        '‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏ö‡∏∏‡∏Ñ‡∏•‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡∏≠‡∏á‡∏Ñ‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏® ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ó‡∏≤‡∏á‡∏ö‡∏Å ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô ‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡∏≤‡∏°‡∏à‡∏£‡∏£‡∏¢‡∏≤‡∏ö‡∏£‡∏£‡∏ì‡∏ß‡∏¥‡∏ä‡∏≤‡∏ä‡∏µ‡∏û',
        '‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏ö‡∏∏‡∏Ñ‡∏•‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏® ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ó‡∏≤‡∏á‡∏ö‡∏Å ‡πÇ‡∏î‡∏¢‡∏ú‡∏™‡∏°‡∏ú‡∏™‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏°‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢',
        '‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏ö‡∏∏‡∏Ñ‡∏•‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£ ‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≠‡∏î ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡∏≠‡∏á‡∏Ñ‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô'
    ],
    'career_prospects': [
        '‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®',
        '‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°',
        '‡∏ô‡∏±‡∏Å‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÅ‡∏•‡∏∞‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°',
        '‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô',
        '‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡πÅ‡∏•‡∏∞‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤'
    ]
}

def generate_unique_assessment_id():
    """Generate unique assessment ID with timestamp and UUID"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    short_uuid = str(uuid.uuid4())[:8]
    return f"ASSESS_{timestamp}_{short_uuid}"

# AI and File Processing Functions
def check_ai_availability():
    """Check if AI API is available"""
    try:
        api_key = st.secrets.get("OPENAI_API_KEY")
        return api_key is not None
    except:
        return False

# Configuration for OpenAI models
OPENAI_MODELS = {
    "gpt-3.5-turbo": "GPT-3.5 Turbo (Fast & Affordable)",
    "gpt-4o-mini": "GPT-4o Mini (Balanced)",
    "gpt-4o": "GPT-4o (Advanced)",
    "gpt-4-turbo": "GPT-4 Turbo (Most Capable)",
}

# Default model - change this to your preferred model
DEFAULT_MODEL = "gpt-3.5-turbo"

def extract_text_from_file(uploaded_file):
    """Extract text from uploaded files"""
    try:
        if uploaded_file.type == "text/plain":
            return str(uploaded_file.read(), "utf-8")
        elif uploaded_file.type == "application/pdf":
            return extract_pdf_content(uploaded_file)
        elif uploaded_file.type in ["application/vnd.ms-powerpoint", 
                                   "application/vnd.openxmlformats-officedocument.presentationml.presentation"]:
            return extract_pptx_content(uploaded_file)
        else:
            # Generate mock content for unsupported formats
            return generate_mock_content_from_filename(uploaded_file.name)
    except Exception as e:
        st.error(f"Error extracting content: {e}")
        return generate_mock_content_from_filename(uploaded_file.name)

def extract_pdf_content(uploaded_file):
    """Extract content from PDF (mock implementation)"""
    # In a real implementation, you would use libraries like PyPDF2 or pdfplumber
    # For demo purposes, we'll generate relevant content based on filename
    filename = uploaded_file.name
    return generate_mock_content_from_filename(filename)

def extract_pptx_content(uploaded_file):
    """Extract content from PowerPoint (mock implementation)"""
    # In a real implementation, you would use python-pptx library
    # For demo purposes, we'll generate relevant content based on filename
    filename = uploaded_file.name
    return generate_mock_content_from_filename(filename)

def generate_mock_content_from_filename(filename):
    """Generate mock content based on filename"""
    base_content = f"""
# Extracted from: {filename}
Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Course Content Analysis

### Introduction to Environmental Management
Environmental management requires systematic integration of technology and community participation.
Modern challenges demand innovative solutions using GIS, Remote Sensing, and advanced modeling techniques.

### Technology Applications
- Geographic Information Systems (GIS) for spatial analysis
- Remote sensing technology for environmental monitoring
- Statistical analysis and data interpretation methods
- Sustainable development approaches with community involvement

### Research Methodologies
Systematic research approaches ensure reliable data collection and analysis.
Literature review processes help identify knowledge gaps and research opportunities.
Integration of multidisciplinary knowledge provides comprehensive understanding.

### Communication and Knowledge Transfer
Effective communication requires understanding target audiences and selecting appropriate channels.
Visual presentations, charts, and multimedia resources enhance learning effectiveness.
Public participation and stakeholder engagement are essential for sustainable solutions.

### Case Studies and Applications
Real-world examples demonstrate practical applications of theoretical concepts.
Community-based research projects show integration of technology and participation.
Environmental monitoring systems provide data for evidence-based decision making.
    """
    
    # Add specific content based on filename keywords
    filename_lower = filename.lower()
    
    if '‡∏ô‡πâ‡∏≥' in filename_lower or 'water' in filename_lower:
        base_content += """

### Water Resource Management
Sustainable water resource management requires comprehensive planning and community participation.
GIS technology enables watershed analysis and water quality assessment.
Integrated water resource management considers multiple stakeholders and uses.
"""
    
    if '‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®' in filename_lower or 'climate' in filename_lower:
        base_content += """

### Climate Change Management
Climate monitoring technology provides essential data for understanding changes.
Adaptation and mitigation strategies require integrated approaches.
Carbon capture and renewable energy technologies offer solutions.
"""
    
    if '‡∏ß‡∏¥‡∏à‡∏±‡∏¢' in filename_lower or 'research' in filename_lower:
        base_content += """

### Research Methodology
Systematic literature review ensures comprehensive knowledge base.
Data collection methods must be appropriate for research objectives.
Statistical analysis and interpretation require careful consideration.
Academic writing standards ensure clear communication of results.
"""
    
    return base_content

@st.cache_data
def generate_ai_analysis(content_hash, course_code, use_ai=False, model_name=DEFAULT_MODEL):
    """Generate AI analysis using OpenAI API or fall back to mock analysis"""
    
    if use_ai and check_ai_availability():
        try:
            from openai import OpenAI
            
            # Initialize OpenAI client
            client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
            
            # Get course information
            course_info = COURSE_DESCRIPTIONS.get(course_code, {})
            course_name = course_info.get('name', 'Unknown Course')
            course_clos = course_info.get('clo', {})
            course_keywords = course_info.get('keywords', {})
            
            # Prepare CLO information for the prompt
            clo_details = []
            for clo_code, clo_desc in course_clos.items():
                keywords = course_keywords.get(clo_code, [])
                clo_details.append(f"{clo_code}: {clo_desc}\nKeywords: {', '.join(keywords)}")
            
            # Create the analysis prompt
            system_prompt = """You are an expert educational assessment AI specializing in analyzing course content alignment with learning outcomes. 
            You provide detailed, accurate assessments of how well content matches Course Learning Outcomes (CLOs).
            Respond in JSON format with scores, confidence levels, and insights."""
            
            user_prompt = f"""Analyze the following content for alignment with Course Learning Outcomes (CLOs).

Course: {course_code} - {course_name}

Course Learning Outcomes:
{chr(10).join(clo_details)}

Content to analyze:
{content_hash[:1000]}  # Using first 1000 chars as sample

For each CLO, provide:
1. A score from 0-100 indicating alignment percentage
2. A confidence level from 0-1 indicating your certainty
3. List of keywords found from the CLO's keyword list
4. 2-3 specific insights about the alignment

Also provide 3-5 overall recommendations for improvement in Thai language.

Return the response in this exact JSON format:
{{
    "clo_analysis": {{
        "CLO1": {{
            "score": 85,
            "confidence": 0.92,
            "found_keywords": ["keyword1", "keyword2"],
            "insights": ["insight1", "insight2", "insight3"]
        }},
        // ... other CLOs
    }},
    "recommendations": ["recommendation1", "recommendation2", "recommendation3"]
}}"""

            # Call OpenAI API
            response = client.chat.completions.create(
                model=model_name,  # Use configurable model
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,  # Lower temperature for more consistent analysis
                response_format={"type": "json_object"}  # Ensure JSON response
            )
            
            # Parse the response
            import json
            ai_response = json.loads(response.choices[0].message.content)
            
            # Format results to match expected structure
            ai_results = {
                'ai_generated': True,
                'analysis_id': content_hash[:8],
                'content_analysis': {},
                'recommendations': ai_response.get('recommendations', []),
                'confidence_scores': {},
                'model_used': response.model,
                'usage': {
                    'prompt_tokens': response.usage.prompt_tokens,
                    'completion_tokens': response.usage.completion_tokens,
                    'total_tokens': response.usage.total_tokens
                }
            }
            
            # Process CLO analysis
            clo_analysis = ai_response.get('clo_analysis', {})
            for clo_code in course_clos.keys():
                if clo_code in clo_analysis:
                    clo_data = clo_analysis[clo_code]
                    ai_results['content_analysis'][clo_code] = {
                        'score': clo_data.get('score', 70),
                        'confidence': clo_data.get('confidence', 0.8),
                        'found_keywords': clo_data.get('found_keywords', []),
                        'ai_insights': clo_data.get('insights', [
                            f"AI analysis completed for {clo_code}",
                            f"Confidence level: {clo_data.get('confidence', 0.8)*100:.0f}%",
                            f"Alignment score: {clo_data.get('score', 70)}%"
                        ])
                    }
                else:
                    # Fallback if CLO not in response
                    ai_results['content_analysis'][clo_code] = {
                        'score': 70,
                        'confidence': 0.75,
                        'found_keywords': [],
                        'ai_insights': [
                            f"Limited alignment detected for {clo_code}",
                            "Consider adding more relevant content",
                            "Review CLO requirements"
                        ]
                    }
            
            # Add Thai recommendations if not provided
            if not ai_results['recommendations']:
                ai_results['recommendations'] = [
                    "‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö CLO ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥",
                    "‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô",
                    "‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏ì‡∏µ‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"
                ]
            
            # Log API usage for monitoring
            st.sidebar.info(f"ü§ñ AI Tokens Used: {ai_results['usage']['total_tokens']}")
            
            return ai_results
            
        except Exception as e:
            # Log error and fall back to mock analysis
            error_msg = f"AI analysis failed (Model: {model_name}): {str(e)}."
            if "model_not_found" in str(e) or "does not exist" in str(e):
                error_msg += f"\n\nAvailable models: {', '.join(OPENAI_MODELS.keys())}"
                error_msg += f"\n\nPlease try using 'gpt-3.5-turbo' or check your API access."
            error_msg += "\n\nUsing mock analysis instead."
            st.warning(error_msg)
            # Continue to mock analysis below
    
    # Mock analysis implementation (existing code)
    # Create deterministic seed from content and course
    deterministic_seed = hash(f"{content_hash}_{course_code}") % (2**32)
    random.seed(deterministic_seed)
    
    course_info = COURSE_DESCRIPTIONS.get(course_code, {})
    course_clos = course_info.get('clo', {})
    
    ai_results = {
        'ai_generated': False,  # False for mock
        'analysis_id': content_hash[:8],
        'content_analysis': {},
        'recommendations': [],
        'confidence_scores': {}
    }
    
    # Deterministic analysis for each CLO
    clo_list = sorted(course_clos.items())
    for i, (clo_code, clo_desc) in enumerate(clo_list):
        keywords = course_info.get('keywords', {}).get(clo_code, [])
        
        # Deterministic keyword selection based on content
        content_words = content_hash.lower()
        found_keywords = []
        for keyword in keywords[:4]:
            if any(char in content_words for char in keyword.lower()[:3]):
                found_keywords.append(keyword)
        
        # Deterministic scoring based on content characteristics
        content_score = len(content_hash) % 30 + 65
        clo_adjustment = (ord(clo_code[-1]) % 15) - 7
        base_score = max(60, min(95, content_score + clo_adjustment))
        
        # Enhanced AI confidence
        base_confidence = 0.90
        keyword_bonus = len(found_keywords) * 0.025
        content_length_bonus = min(0.04, len(content_hash) / 800)
        score_bonus = max(0, (base_score - 70) * 0.002)
        course_match_bonus = 0.015 if course_code in content_hash else 0
        
        confidence = min(0.995, base_confidence + keyword_bonus + content_length_bonus + score_bonus + course_match_bonus)
        
        ai_results['content_analysis'][clo_code] = {
            'score': base_score,
            'confidence': round(confidence, 3),
            'found_keywords': found_keywords,
            'ai_insights': [
                f"‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {clo_code} ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á",
                f"‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {', '.join(found_keywords[:2]) if found_keywords else '‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢'}",
                f"‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°: {clo_desc[:40]}..."
            ]
        }
    
    # Deterministic recommendations in Thai
    all_recommendations = [
        "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏ì‡∏µ‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏ò‡∏£‡∏£‡∏°",
        "‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡∏î‡πâ‡∏ß‡∏¢‡πÅ‡∏ú‡∏ô‡∏†‡∏π‡∏°‡∏¥‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö",
        "‡πÄ‡∏™‡∏£‡∏¥‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô",
        "‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏§‡∏©‡∏é‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥",
        "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î",
        "‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤"
    ]
    
    rec_indices = [int(content_hash[i*2:i*2+2], 16) % len(all_recommendations) for i in range(3)]
    ai_results['recommendations'] = [all_recommendations[i] for i in rec_indices]
    
    return ai_results

class MultiLevelAssessmentEngine:
    """Multi-Level Assessment Engine for CLO-PLO-YLO alignment with AI support"""
    
    def __init__(self):
        self.course_descriptions = COURSE_DESCRIPTIONS
        self.ylo_structure = YLO_STRUCTURE
        self.plos = ENHANCED_PLOS
    
    def preprocess_text(self, text):
        """Clean and preprocess text"""
        if not text:
            return ""
        text = re.sub(r'[^\w\s]', ' ', text.lower())
        text = re.sub(r'\s+', ' ', text.strip())
        return text
    
    def calculate_clo_alignment(self, content, course_code, ai_analysis=None):
        """Calculate Course Learning Outcome alignment with optional AI support - deterministic"""
        if course_code not in self.course_descriptions:
            return {}
        
        course_data = self.course_descriptions[course_code]
        content_processed = self.preprocess_text(content)
        
        # Create deterministic seed for this analysis
        analysis_seed = hash(f"{content_processed[:100]}_{course_code}") % (2**32)
        
        clo_results = {}
        
        for clo_code, clo_description in course_data['clo'].items():
            # Find keywords for this CLO
            keywords = course_data['keywords'].get(clo_code, [])
            found_keywords = []
            
            for keyword in keywords:
                keyword_processed = self.preprocess_text(keyword)
                if keyword_processed in content_processed:
                    found_keywords.append(keyword)
            
            # Calculate base score - deterministic
            if keywords:
                coverage = len(found_keywords) / len(keywords)
                base_score = 50
                coverage_score = coverage * 40
                
                # Bonus for description relevance - deterministic
                desc_words = self.preprocess_text(clo_description).split()
                desc_matches = sum(1 for word in desc_words if word in content_processed)
                desc_bonus = min(desc_matches * 2, 10)
                
                final_score = min(100, base_score + coverage_score + desc_bonus)
            else:
                final_score = 50
            
            # Apply AI enhancement if available - keep AI scores consistent
            confidence = 0.8  # Default confidence
            ai_insights = []
            
            if ai_analysis and clo_code in ai_analysis.get('content_analysis', {}):
                ai_data = ai_analysis['content_analysis'][clo_code]
                ai_score = ai_data['score']
                confidence = ai_data['confidence']
                
                # Weighted combination of rule-based and AI scores - deterministic
                final_score = (final_score * 0.4) + (ai_score * 0.6)
                
                # Add AI insights
                ai_insights = ai_data.get('ai_insights', [])
            
            clo_results[clo_code] = {
                'score': round(final_score, 1),
                'description': clo_description,
                'found_keywords': found_keywords,
                'total_keywords': len(keywords),
                'coverage': len(found_keywords) / len(keywords) if keywords else 0,
                'confidence': round(confidence, 2),
                'ai_insights': ai_insights,
                'ai_enhanced': ai_analysis is not None and ai_analysis.get('ai_generated', False)
            }
        
        return clo_results
    
    def calculate_multi_level_alignment(self, content, course_code, ai_analysis=None):
        """Calculate alignment across CLO-PLO-YLO levels with AI support"""
        # Create content hash for tracking and ensure unique ID
        content_hash = hashlib.md5(content.encode()).hexdigest()
        
        results = {
            'assessment_id': generate_unique_assessment_id(),  # Use new unique ID function
            'course_code': course_code,
            'course_name': self.course_descriptions.get(course_code, {}).get('name', 'Unknown'),
            'content_hash': content_hash,
            'content_length': len(content),
            'content_preview': content[:200],
            'clo_results': {},
            'plo_results': {},
            'ylo_results': {},
            'alignment_matrix': {},
            'overall_scores': {},
            'ai_enhanced': ai_analysis is not None and ai_analysis.get('ai_generated', False),
            'ai_recommendations': ai_analysis.get('recommendations', []) if ai_analysis and ai_analysis.get('ai_generated', False) else []
        }
        
        # 1. CLO Analysis with AI support
        clo_results = self.calculate_clo_alignment(content, course_code, ai_analysis)
        results['clo_results'] = clo_results
        
        # 2. PLO Analysis (mapped from CLOs) - Fixed calculation
        if course_code in self.course_descriptions:
            course_data = self.course_descriptions[course_code]
            mapped_plos = course_data.get('plo_mapping', [])
            
            for plo_code in mapped_plos:
                # Find CLOs that specifically contribute to this PLO
                # Based on course content and CLO descriptions
                related_clos = []
                
                # Map CLOs to PLOs based on course design
                if plo_code == 'PLO1':  # Technology and Participation
                    # CLOs that involve technology, tools, sustainability
                    related_clos = [clo for clo in clo_results.keys() 
                                   if any(keyword in ['‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ', 'technology', 'GIS', '‡∏£‡∏∞‡∏ö‡∏ö', '‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô', 'sustainable'] 
                                         for keyword in course_data.get('keywords', {}).get(clo, []))]
                elif plo_code == 'PLO2':  # Research and Integration  
                    # CLOs that involve research, methodology, analysis
                    related_clos = [clo for clo in clo_results.keys()
                                   if any(keyword in ['‡∏ß‡∏¥‡∏à‡∏±‡∏¢', 'research', '‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£', 'methodology', '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå', 'analysis', '‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£', 'integrate']
                                         for keyword in course_data.get('keywords', {}).get(clo, []))]
                elif plo_code == 'PLO3':  # Communication and Transfer
                    # CLOs that involve communication, presentation, writing
                    related_clos = [clo for clo in clo_results.keys()
                                   if any(keyword in ['‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£', 'communicate', '‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠', 'present', '‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô', 'writing', '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô', 'report']
                                         for keyword in course_data.get('keywords', {}).get(clo, []))]
                
                # Fallback: if no specific mapping found, use all CLOs but with weights
                if not related_clos:
                    related_clos = list(clo_results.keys())
                
                # Calculate PLO score based on related CLOs only
                if related_clos:
                    # Weight CLOs based on relevance to PLO
                    weighted_scores = []
                    for clo in related_clos:
                        weight = 1.0  # Default weight
                        
                        # Adjust weight based on CLO-PLO relevance
                        clo_keywords = course_data.get('keywords', {}).get(clo, [])
                        if plo_code == 'PLO1' and any(kw in ['‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ', 'technology', 'GIS'] for kw in clo_keywords):
                            weight = 1.2
                        elif plo_code == 'PLO2' and any(kw in ['‡∏ß‡∏¥‡∏à‡∏±‡∏¢', 'research', '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå'] for kw in clo_keywords):
                            weight = 1.2  
                        elif plo_code == 'PLO3' and any(kw in ['‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£', 'communicate', '‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠'] for kw in clo_keywords):
                            weight = 1.2
                        
                        weighted_scores.append(clo_results[clo]['score'] * weight)
                    
                    plo_score = sum(weighted_scores) / len(weighted_scores)
                    avg_confidence = sum(clo_results[clo]['confidence'] for clo in related_clos) / len(related_clos)
                else:
                    plo_score = 0
                    avg_confidence = 0
                
                results['plo_results'][plo_code] = {
                    'score': round(plo_score, 1),
                    'related_clos': related_clos,
                    'description': self.plos[plo_code]['description'],
                    'confidence': avg_confidence
                }
        
        # 3. YLO Analysis (mapped from PLOs)
        if course_code in self.course_descriptions:
            course_data = self.course_descriptions[course_code]
            mapped_ylos = course_data.get('ylo_mapping', [])
            
            for ylo_code in mapped_ylos:
                ylo_data = self.ylo_structure[ylo_code]
                related_plos = ylo_data['plo_mapping']
                
                # Calculate YLO score based on PLO scores
                ylo_scores = []
                confidences = []
                for plo_code in related_plos:
                    if plo_code in results['plo_results']:
                        ylo_scores.append(results['plo_results'][plo_code]['score'])
                        confidences.append(results['plo_results'][plo_code]['confidence'])
                
                ylo_score = sum(ylo_scores) / len(ylo_scores) if ylo_scores else 0
                avg_confidence = sum(confidences) / len(confidences) if confidences else 0
                
                # Calculate cognitive multiplier based on cognitive level
                cognitive_weights = {
                    'Understanding': 1.0,
                    'Applying': 1.1,
                    'Evaluating': 1.2,
                    'Creating': 1.3
                }
                cognitive_multiplier = cognitive_weights.get(ylo_data['cognitive_level'], 1.0)
                
                results['ylo_results'][ylo_code] = {
                    'score': round(ylo_score, 1),
                    'related_plos': related_plos,
                    'description': ylo_data['description'],
                    'level': ylo_data['level'],
                    'cognitive_level': ylo_data['cognitive_level'],
                    'confidence': round(avg_confidence, 3),
                    'cognitive_multiplier': cognitive_multiplier
                }
        
        # 4. Create alignment matrix
        results['alignment_matrix'] = self.create_alignment_matrix(results)
        
        # 5. Calculate overall scores - Fixed to show different values
        # CLO Average - direct average of all CLO scores
        clo_average = sum(clo['score'] for clo in clo_results.values()) / len(clo_results) if clo_results else 0
        
        # PLO Average - weighted by PLO importance in the program
        if results['plo_results']:
            plo_weighted_sum = 0
            total_weight = 0
            for plo_code, plo_data in results['plo_results'].items():
                weight = self.plos[plo_code]['weight'] / 100  # Convert percentage to decimal
                plo_weighted_sum += plo_data['score'] * weight
                total_weight += weight
            plo_average = plo_weighted_sum / total_weight if total_weight > 0 else 0
        else:
            plo_average = 0
        
        # YLO Average - consider cognitive complexity
        if results['ylo_results']:
            ylo_weighted_sum = 0
            total_cognitive_weight = 0
            for ylo_code, ylo_data in results['ylo_results'].items():
                # Weight by cognitive level complexity
                cognitive_weights = {
                    'Understanding': 1.0,
                    'Applying': 1.1, 
                    'Evaluating': 1.2,
                    'Creating': 1.3
                }
                weight = cognitive_weights.get(ylo_data['cognitive_level'], 1.0)
                ylo_weighted_sum += ylo_data['score'] * weight
                total_cognitive_weight += weight
            ylo_average = ylo_weighted_sum / total_cognitive_weight if total_cognitive_weight > 0 else 0
        else:
            ylo_average = 0
        
        # Overall confidence
        overall_confidence = sum(clo['confidence'] for clo in clo_results.values()) / len(clo_results) if clo_results else 0
        
        results['overall_scores'] = {
            'clo_average': round(clo_average, 1),
            'plo_average': round(plo_average, 1), 
            'ylo_average': round(ylo_average, 1),
            'overall_confidence': round(overall_confidence, 3),
            'calculation_method': {
                'clo': 'Simple average of all CLO scores',
                'plo': 'Weighted average by PLO importance (35%, 35%, 30%)',
                'ylo': 'Weighted average by cognitive complexity'
            }
        }
        
        return results
    
    def create_alignment_matrix(self, results):
        """Create alignment matrix showing CLO-PLO-YLO relationships"""
        matrix = {
            'clo_to_plo': {},
            'plo_to_ylo': {},
            'clo_to_ylo': {}
        }
        
        # CLO to PLO mapping
        for plo_code, plo_data in results['plo_results'].items():
            related_clos = plo_data['related_clos']
            for clo_code in related_clos:
                if clo_code not in matrix['clo_to_plo']:
                    matrix['clo_to_plo'][clo_code] = []
                matrix['clo_to_plo'][clo_code].append(plo_code)
        
        # PLO to YLO mapping
        for ylo_code, ylo_data in results['ylo_results'].items():
            related_plos = ylo_data['related_plos']
            for plo_code in related_plos:
                if plo_code not in matrix['plo_to_ylo']:
                    matrix['plo_to_ylo'][plo_code] = []
                matrix['plo_to_ylo'][plo_code].append(ylo_code)
        
        return matrix

# NEW: Multi-File Aggregation Functions
class MultiFileAggregator:
    """Aggregate and analyze multiple files from the same course"""
    
    def __init__(self):
        self.engine = MultiLevelAssessmentEngine()
    
    def aggregate_assessments(self, file_assessments):
        """Aggregate multiple file assessments into comprehensive analysis"""
        if not file_assessments:
            return None
        
        # Get course info from first assessment
        course_code = file_assessments[0]['course_code']
        course_name = file_assessments[0]['course_name']
        
        aggregated_results = {
            'assessment_id': f"MULTI_{generate_unique_assessment_id()}",
            'course_code': course_code,
            'course_name': course_name,
            'total_files': len(file_assessments),
            'file_names': [f['file_name'] for f in file_assessments],
            'aggregated_clo': self._aggregate_clo_scores(file_assessments),
            'aggregated_plo': self._aggregate_plo_scores(file_assessments),
            'aggregated_ylo': self._aggregate_ylo_scores(file_assessments),
            'coverage_analysis': self._analyze_coverage(file_assessments),
            'completeness_analysis': self._analyze_completeness(file_assessments),
            'improvement_metrics': self._calculate_improvement_metrics(file_assessments),
            'comprehensive_recommendations': self._generate_comprehensive_recommendations(file_assessments)
        }
        
        return aggregated_results
    
    def _aggregate_clo_scores(self, assessments):
        """Aggregate CLO scores across multiple files"""
        clo_aggregated = {}
        clo_keywords_found = defaultdict(set)
        
        for assessment in assessments:
            for clo_code, clo_data in assessment['clo_results'].items():
                if clo_code not in clo_aggregated:
                    clo_aggregated[clo_code] = {
                        'scores': [],
                        'description': clo_data['description'],
                        'all_keywords': set(),
                        'confidence_scores': []
                    }
                
                clo_aggregated[clo_code]['scores'].append(clo_data['score'])
                clo_aggregated[clo_code]['all_keywords'].update(clo_data['found_keywords'])
                clo_aggregated[clo_code]['confidence_scores'].append(clo_data.get('confidence', 0.8))
        
        # Calculate aggregated metrics
        results = {}
        for clo_code, data in clo_aggregated.items():
            results[clo_code] = {
                'description': data['description'],
                'avg_score': round(sum(data['scores']) / len(data['scores']), 1),
                'max_score': round(max(data['scores']), 1),
                'min_score': round(min(data['scores']), 1),
                'score_improvement': round(max(data['scores']) - min(data['scores']), 1),
                'unique_keywords_found': list(data['all_keywords']),
                'keyword_count': len(data['all_keywords']),
                'file_coverage': len(data['scores']),
                'avg_confidence': round(sum(data['confidence_scores']) / len(data['confidence_scores']), 2)
            }
        
        return results
    
    def _aggregate_plo_scores(self, assessments):
        """Aggregate PLO scores across multiple files"""
        plo_aggregated = {}
        
        for assessment in assessments:
            for plo_code, plo_data in assessment['plo_results'].items():
                if plo_code not in plo_aggregated:
                    plo_aggregated[plo_code] = {
                        'scores': [],
                        'description': plo_data['description'],
                        'all_related_clos': set()
                    }
                
                plo_aggregated[plo_code]['scores'].append(plo_data['score'])
                plo_aggregated[plo_code]['all_related_clos'].update(plo_data['related_clos'])
        
        # Calculate aggregated metrics
        results = {}
        for plo_code, data in plo_aggregated.items():
            results[plo_code] = {
                'description': data['description'],
                'avg_score': round(sum(data['scores']) / len(data['scores']), 1),
                'max_score': round(max(data['scores']), 1),
                'min_score': round(min(data['scores']), 1),
                'score_improvement': round(max(data['scores']) - min(data['scores']), 1),
                'related_clos': list(data['all_related_clos']),
                'file_coverage': len(data['scores'])
            }
        
        return results
    
    def _aggregate_ylo_scores(self, assessments):
        """Aggregate YLO scores across multiple files"""
        ylo_aggregated = {}
        
        for assessment in assessments:
            for ylo_code, ylo_data in assessment['ylo_results'].items():
                if ylo_code not in ylo_aggregated:
                    ylo_aggregated[ylo_code] = {
                        'scores': [],
                        'description': ylo_data['description'],
                        'level': ylo_data['level'],
                        'cognitive_level': ylo_data['cognitive_level']
                    }
                
                ylo_aggregated[ylo_code]['scores'].append(ylo_data['score'])
        
        # Calculate aggregated metrics
        results = {}
        for ylo_code, data in ylo_aggregated.items():
            results[ylo_code] = {
                'description': data['description'],
                'level': data['level'],
                'cognitive_level': data['cognitive_level'],
                'avg_score': round(sum(data['scores']) / len(data['scores']), 1),
                'max_score': round(max(data['scores']), 1),
                'min_score': round(min(data['scores']), 1),
                'score_improvement': round(max(data['scores']) - min(data['scores']), 1),
                'file_coverage': len(data['scores'])
            }
        
        return results
    
    def _analyze_coverage(self, assessments):
        """Analyze how comprehensively the files cover learning outcomes"""
        total_files = len(assessments)
        
        # CLO Coverage
        clo_coverage = {}
        all_clos = set()
        for assessment in assessments:
            all_clos.update(assessment['clo_results'].keys())
        
        for clo in all_clos:
            files_with_clo = sum(1 for a in assessments if clo in a['clo_results'] and a['clo_results'][clo]['score'] >= 70)
            clo_coverage[clo] = {
                'files_meeting_threshold': files_with_clo,
                'coverage_percentage': round((files_with_clo / total_files) * 100, 1)
            }
        
        # PLO Coverage
        plo_coverage = {}
        all_plos = set()
        for assessment in assessments:
            all_plos.update(assessment['plo_results'].keys())
        
        for plo in all_plos:
            files_with_plo = sum(1 for a in assessments if plo in a['plo_results'] and a['plo_results'][plo]['score'] >= 70)
            plo_coverage[plo] = {
                'files_meeting_threshold': files_with_plo,
                'coverage_percentage': round((files_with_plo / total_files) * 100, 1)
            }
        
        return {
            'clo_coverage': clo_coverage,
            'plo_coverage': plo_coverage,
            'overall_clo_coverage': round(sum(c['coverage_percentage'] for c in clo_coverage.values()) / len(clo_coverage), 1) if clo_coverage else 0,
            'overall_plo_coverage': round(sum(p['coverage_percentage'] for p in plo_coverage.values()) / len(plo_coverage), 1) if plo_coverage else 0
        }
    
    def _analyze_completeness(self, assessments):
        """Analyze how complete the learning outcomes are across all files"""
        if not assessments:
            return {}
        
        # Get expected outcomes from course
        course_code = assessments[0]['course_code']
        course_info = COURSE_DESCRIPTIONS.get(course_code, {})
        expected_clos = set(course_info.get('clo', {}).keys())
        expected_plos = set(course_info.get('plo_mapping', []))
        expected_ylos = set(course_info.get('ylo_mapping', []))
        
        # Track which outcomes are well-covered (>= 70% in at least one file)
        well_covered_clos = set()
        well_covered_plos = set()
        well_covered_ylos = set()
        
        for assessment in assessments:
            for clo, data in assessment['clo_results'].items():
                if data['score'] >= 70:
                    well_covered_clos.add(clo)
            
            for plo, data in assessment['plo_results'].items():
                if data['score'] >= 70:
                    well_covered_plos.add(plo)
            
            for ylo, data in assessment['ylo_results'].items():
                if data['score'] >= 70:
                    well_covered_ylos.add(ylo)
        
        return {
            'clo_completeness': {
                'expected': len(expected_clos),
                'well_covered': len(well_covered_clos),
                'percentage': round((len(well_covered_clos) / len(expected_clos)) * 100, 1) if expected_clos else 0,
                'missing': list(expected_clos - well_covered_clos)
            },
            'plo_completeness': {
                'expected': len(expected_plos),
                'well_covered': len(well_covered_plos),
                'percentage': round((len(well_covered_plos) / len(expected_plos)) * 100, 1) if expected_plos else 0,
                'missing': list(expected_plos - well_covered_plos)
            },
            'ylo_completeness': {
                'expected': len(expected_ylos),
                'well_covered': len(well_covered_ylos),
                'percentage': round((len(well_covered_ylos) / len(expected_ylos)) * 100, 1) if expected_ylos else 0,
                'missing': list(expected_ylos - well_covered_ylos)
            },
            'overall_completeness': round(
                (len(well_covered_clos) / len(expected_clos) * 100 +
                 len(well_covered_plos) / len(expected_plos) * 100 +
                 len(well_covered_ylos) / len(expected_ylos) * 100) / 3, 1
            ) if expected_clos and expected_plos and expected_ylos else 0
        }
    
    def _calculate_improvement_metrics(self, assessments):
        """Calculate how much the multiple files improve learning outcomes"""
        if len(assessments) < 2:
            return {
                'clo_improvement': 0,
                'plo_improvement': 0,
                'ylo_improvement': 0,
                'overall_improvement': 0,
                'message': '‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á'
            }
        
        # Calculate improvement from single file to multiple files
        first_assessment = assessments[0]
        aggregated_clos = self._aggregate_clo_scores(assessments)
        aggregated_plos = self._aggregate_plo_scores(assessments)
        aggregated_ylos = self._aggregate_ylo_scores(assessments)
        
        # CLO Improvement
        clo_improvements = []
        for clo_code in aggregated_clos:
            if clo_code in first_assessment['clo_results']:
                first_score = first_assessment['clo_results'][clo_code]['score']
                best_score = aggregated_clos[clo_code]['max_score']
                improvement = best_score - first_score
                clo_improvements.append(improvement)
        
        # PLO Improvement
        plo_improvements = []
        for plo_code in aggregated_plos:
            if plo_code in first_assessment['plo_results']:
                first_score = first_assessment['plo_results'][plo_code]['score']
                best_score = aggregated_plos[plo_code]['max_score']
                improvement = best_score - first_score
                plo_improvements.append(improvement)
        
        # YLO Improvement
        ylo_improvements = []
        for ylo_code in aggregated_ylos:
            if ylo_code in first_assessment['ylo_results']:
                first_score = first_assessment['ylo_results'][ylo_code]['score']
                best_score = aggregated_ylos[ylo_code]['max_score']
                improvement = best_score - first_score
                ylo_improvements.append(improvement)
        
        avg_clo_improvement = round(sum(clo_improvements) / len(clo_improvements), 1) if clo_improvements else 0
        avg_plo_improvement = round(sum(plo_improvements) / len(plo_improvements), 1) if plo_improvements else 0
        avg_ylo_improvement = round(sum(ylo_improvements) / len(ylo_improvements), 1) if ylo_improvements else 0
        
        return {
            'clo_improvement': avg_clo_improvement,
            'plo_improvement': avg_plo_improvement,
            'ylo_improvement': avg_ylo_improvement,
            'overall_improvement': round((avg_clo_improvement + avg_plo_improvement + avg_ylo_improvement) / 3, 1),
            'improvement_percentage': round(
                ((avg_clo_improvement + avg_plo_improvement + avg_ylo_improvement) / 3) / 70 * 100, 1
            ),
            'message': f'‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ {round((avg_clo_improvement + avg_plo_improvement + avg_ylo_improvement) / 3, 1)}%'
        }
    
    def _generate_comprehensive_recommendations(self, assessments):
        """Generate recommendations based on multi-file analysis"""
        recommendations = []
        
        completeness = self._analyze_completeness(assessments)
        coverage = self._analyze_coverage(assessments)
        
        # CLO-based recommendations
        if completeness['clo_completeness']['missing']:
            missing_clos = ', '.join(completeness['clo_completeness']['missing'])
            recommendations.append(f"‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° CLO ‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î: {missing_clos}")
        
        if coverage['overall_clo_coverage'] < 80:
            recommendations.append("‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô CLO ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠")
        
        # PLO-based recommendations
        if completeness['plo_completeness']['percentage'] < 100:
            recommendations.append("‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° PLO ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£")
        
        # YLO-based recommendations
        if completeness['ylo_completeness']['percentage'] < 100:
            recommendations.append("‡πÄ‡∏™‡∏£‡∏¥‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° YLO ‡∏ó‡∏∏‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ")
        
        # Overall completeness
        if completeness['overall_completeness'] >= 90:
            recommendations.append("üåü ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏£‡∏ß‡∏°‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° ‡∏Ñ‡∏ß‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏ß‡πâ")
        elif completeness['overall_completeness'] >= 75:
            recommendations.append("‚úÖ ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏£‡∏ß‡∏°‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÑ‡∏î‡πâ")
        else:
            recommendations.append("‚ö†Ô∏è ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á")
        
        # File-specific recommendations
        if len(assessments) < 3:
            recommendations.append("‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 3-4 ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô")
        
        return recommendations[:8]  # Limit to 8 recommendations

# Display Functions (keeping existing ones and adding new ones)
def create_enhanced_gauge_chart(score, title="Score", confidence=None):
    """Create enhanced gauge chart with confidence indicator"""
    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=score,
        domain={'x': [0, 1], 'y': [0, 1]},
        title={'text': title, 'font': {'size': 18, 'color': '#333'}},
        delta={'reference': 70, 'increasing': {'color': "green"}, 'decreasing': {'color': "red"}},
        gauge={
            'axis': {'range': [None, 100], 'tickwidth': 2, 'tickcolor': "#333"},
            'bar': {'color': "#667eea", 'thickness': 0.25},
            'steps': [
                {'range': [0, 50], 'color': "#ffebee"},
                {'range': [50, 60], 'color': "#fff3e0"},
                {'range': [60, 70], 'color': "#fffde7"},
                {'range': [70, 85], 'color': "#e8f5e8"},
                {'range': [85, 100], 'color': "#e3f2fd"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 70
            }
        }
    ))
    
    # Add confidence indicator if available
    annotations = ["Pass: 70% | Good: 85%"]
    if confidence:
        annotations.append(f"AI Confidence: {confidence*100:.0f}%")
    
    fig.add_annotation(
        x=0.5, y=0.1,
        text=" | ".join(annotations),
        showarrow=False,
        font=dict(size=10, color="#666")
    )
    
    fig.update_layout(
        height=300, 
        margin=dict(t=60, b=40, l=20, r=20),
        font={'family': 'Arial, sans-serif'}
    )
    return fig

def create_multi_level_dashboard(results, key_prefix=""):
    """Create comprehensive multi-level dashboard with enhanced features"""
    st.header("üéØ Multi-Level Learning Outcome Assessment")
    
    # Course Information with enhanced AI status
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        st.subheader(f"üìö {results['course_name']}")
        st.write(f"**Course Code:** {results['course_code']}")
    with col2:
        st.write(f"**Assessment ID:** `{results.get('assessment_id', 'N/A')}`")
        if results.get('ai_enhanced', False):
            st.success("ü§ñ AI Enhanced")
        else:
            st.info("üìä Rule-based")
    with col3:
        if results.get('ai_enhanced', False):
            confidence = results['overall_scores'].get('overall_confidence', 0)
            st.metric("AI Confidence", f"{confidence*100:.0f}%")
        
        # Show content hash for tracking
        content_hash = results.get('content_hash', '')
        if content_hash:
            st.caption(f"Content Hash: `{content_hash[:8]}...`")
    
    # Overall Scores with Enhanced Gauge Charts
    st.subheader("üìä Performance Dashboard")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        clo_avg = results['overall_scores']['clo_average']
        confidence = results['overall_scores'].get('overall_confidence', 0.8)
        fig_clo = create_enhanced_gauge_chart(
            clo_avg, 
            "CLO Average",
            confidence if results.get('ai_enhanced') else None
        )
        st.plotly_chart(fig_clo, use_container_width=True, key=f"{key_prefix}_clo_gauge")
    
    with col2:
        plo_avg = results['overall_scores']['plo_average']
        fig_plo = create_enhanced_gauge_chart(
            plo_avg, 
            "PLO Average",
            confidence if results.get('ai_enhanced') else None
        )
        st.plotly_chart(fig_plo, use_container_width=True, key=f"{key_prefix}_plo_gauge")
    
    with col3:
        ylo_avg = results['overall_scores']['ylo_average']
        fig_ylo = create_enhanced_gauge_chart(
            ylo_avg, 
            "YLO Average",
            confidence if results.get('ai_enhanced') else None
        )
        st.plotly_chart(fig_ylo, use_container_width=True, key=f"{key_prefix}_ylo_gauge")
    
    # Enhanced Overall Status with calculation explanation
    overall_avg = (results['overall_scores']['clo_average'] + 
                   results['overall_scores']['plo_average'] + 
                   results['overall_scores']['ylo_average']) / 3
    
    if overall_avg >= 85:
        st.success(f"üåü **Overall Performance: Excellent** ({overall_avg:.1f}%) - Assessment ID: {results.get('assessment_id', 'N/A')}")
        st.balloons()
    elif overall_avg >= 70:
        st.success(f"‚úÖ **Overall Performance: Good** ({overall_avg:.1f}%) - Assessment ID: {results.get('assessment_id', 'N/A')}")
    elif overall_avg >= 60:
        st.warning(f"‚ö†Ô∏è **Overall Performance: Fair** ({overall_avg:.1f}%) - Assessment ID: {results.get('assessment_id', 'N/A')}")
    else:
        st.error(f"‚ùå **Overall Performance: Needs Improvement** ({overall_avg:.1f}%) - Assessment ID: {results.get('assessment_id', 'N/A')}")
    
    # Enhanced AI Recommendations (if available)
    if results.get('ai_recommendations') and results.get('ai_enhanced'):
        st.subheader("ü§ñ AI Recommendations")
        for i, rec in enumerate(results['ai_recommendations'], 1):
            st.write(f"{i}. {rec}")
        st.markdown("---")
    
    # Enhanced Multi-level Analysis Tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìã CLO Analysis", "üéØ PLO Analysis", "üìà YLO Analysis", "üîó Alignment Matrix", "üìä ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°"])
    
    with tab1:
        display_enhanced_clo_analysis(results['clo_results'], key_prefix)
    
    with tab2:
        display_plo_analysis(results['plo_results'], key_prefix)
    
    with tab3:
        display_ylo_analysis(results['ylo_results'], key_prefix)
    
    with tab4:
        display_alignment_matrix(results, key_prefix)
    
    with tab5:
        display_comprehensive_interpretation(results)

# NEW: Multi-File Results Dashboard
def create_multi_file_dashboard(aggregated_results, key_prefix=""):
    """Create dashboard for multi-file aggregated results"""
    st.header("üìÅ Multi-File Aggregated Assessment Results")
    
    # Overview
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Files", aggregated_results['total_files'])
    with col2:
        st.metric("Course", aggregated_results['course_code'])
    with col3:
        completeness = aggregated_results['completeness_analysis']['overall_completeness']
        st.metric("Overall Completeness", f"{completeness:.1f}%")
    with col4:
        improvement = aggregated_results['improvement_metrics']['overall_improvement']
        st.metric("Avg Improvement", f"+{improvement:.1f}%")
    
    # File list
    with st.expander("üìÑ Analyzed Files"):
        for i, filename in enumerate(aggregated_results['file_names'], 1):
            st.write(f"{i}. {filename}")
    
    # Aggregated CLO Analysis
    st.subheader("üìä Aggregated CLO Analysis")
    
    clo_data = []
    for clo_code, clo_info in aggregated_results['aggregated_clo'].items():
        clo_data.append({
            'CLO': clo_code,
            'Description': clo_info['description'][:50] + '...',
            'Avg Score': f"{clo_info['avg_score']:.1f}%",
            'Max Score': f"{clo_info['max_score']:.1f}%",
            'Improvement': f"+{clo_info['score_improvement']:.1f}%",
            'Keywords Found': clo_info['keyword_count'],
            'File Coverage': f"{clo_info['file_coverage']}/{aggregated_results['total_files']}"
        })
    
    if clo_data:
        clo_df = pd.DataFrame(clo_data)
        st.dataframe(clo_df, use_container_width=True, hide_index=True)
    
    # Visual comparison
    col1, col2 = st.columns(2)
    
    with col1:
        # CLO Score Comparison Chart
        fig_clo = go.Figure()
        
        clo_codes = list(aggregated_results['aggregated_clo'].keys())
        avg_scores = [aggregated_results['aggregated_clo'][clo]['avg_score'] for clo in clo_codes]
        max_scores = [aggregated_results['aggregated_clo'][clo]['max_score'] for clo in clo_codes]
        min_scores = [aggregated_results['aggregated_clo'][clo]['min_score'] for clo in clo_codes]
        
        fig_clo.add_trace(go.Bar(name='Average', x=clo_codes, y=avg_scores, marker_color='#667eea'))
        fig_clo.add_trace(go.Scatter(name='Max', x=clo_codes, y=max_scores, mode='markers', marker=dict(size=10, color='green')))
        fig_clo.add_trace(go.Scatter(name='Min', x=clo_codes, y=min_scores, mode='markers', marker=dict(size=10, color='red')))
        
        fig_clo.update_layout(
            title="CLO Score Distribution",
            xaxis_title="CLO",
            yaxis_title="Score (%)",
            height=400
        )
        st.plotly_chart(fig_clo, use_container_width=True, key=f"{key_prefix}_multi_file_clo_comparison")
    
    with col2:
        # Completeness Pie Chart
        completeness_data = aggregated_results['completeness_analysis']
        
        labels = ['CLO', 'PLO', 'YLO']
        values = [
            completeness_data['clo_completeness']['percentage'],
            completeness_data['plo_completeness']['percentage'],
            completeness_data['ylo_completeness']['percentage']
        ]
        
        fig_complete = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])
        fig_complete.update_layout(
            title="Learning Outcome Completeness",
            height=400
        )
        st.plotly_chart(fig_complete, use_container_width=True, key=f"{key_prefix}_multi_file_completeness")
    
    # Coverage Analysis
    st.subheader("üìà Coverage Analysis")
    
    coverage_data = aggregated_results['coverage_analysis']
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("CLO Coverage", f"{coverage_data['overall_clo_coverage']:.1f}%")
    with col2:
        st.metric("PLO Coverage", f"{coverage_data['overall_plo_coverage']:.1f}%")
    with col3:
        clo_complete = aggregated_results['completeness_analysis']['clo_completeness']['percentage']
        st.metric("CLO Completeness", f"{clo_complete:.1f}%")
    with col4:
        plo_complete = aggregated_results['completeness_analysis']['plo_completeness']['percentage']
        st.metric("PLO Completeness", f"{plo_complete:.1f}%")
    
    # Missing Outcomes
    completeness = aggregated_results['completeness_analysis']
    if completeness['clo_completeness']['missing'] or completeness['plo_completeness']['missing'] or completeness['ylo_completeness']['missing']:
        st.warning("‚ö†Ô∏è Missing Learning Outcomes")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            if completeness['clo_completeness']['missing']:
                st.write("**Missing CLOs:**")
                for clo in completeness['clo_completeness']['missing']:
                    st.write(f"‚Ä¢ {clo}")
        
        with col2:
            if completeness['plo_completeness']['missing']:
                st.write("**Missing PLOs:**")
                for plo in completeness['plo_completeness']['missing']:
                    st.write(f"‚Ä¢ {plo}")
        
        with col3:
            if completeness['ylo_completeness']['missing']:
                st.write("**Missing YLOs:**")
                for ylo in completeness['ylo_completeness']['missing']:
                    st.write(f"‚Ä¢ {ylo}")
    
    # Improvement Metrics
    st.subheader("üìä Improvement Analysis")
    
    improvement = aggregated_results['improvement_metrics']
    
    col1, col2, col3 = st.columns(3)
    with col1:
        fig_improve = go.Figure(go.Indicator(
            mode = "gauge+number",
            value = improvement['improvement_percentage'],
            title = {'text': "Overall Improvement %"},
            gauge = {'axis': {'range': [None, 50]},
                     'bar': {'color': "darkgreen"},
                     'steps' : [
                         {'range': [0, 10], 'color': "lightgray"},
                         {'range': [10, 30], 'color': "lightgreen"},
                         {'range': [30, 50], 'color': "green"}],
                     'threshold' : {'line': {'color': "red", 'width': 4}, 'thickness': 0.75, 'value': 20}}
        ))
        fig_improve.update_layout(height=250)
        st.plotly_chart(fig_improve, use_container_width=True, key=f"{key_prefix}_multi_file_improvement_gauge")
    
    with col2:
        st.write("**Improvement by Level:**")
        st.write(f"‚Ä¢ CLO: +{improvement['clo_improvement']:.1f}%")
        st.write(f"‚Ä¢ PLO: +{improvement['plo_improvement']:.1f}%")
        st.write(f"‚Ä¢ YLO: +{improvement['ylo_improvement']:.1f}%")
    
    with col3:
        st.info(improvement['message'])
    
    # Comprehensive Recommendations
    st.subheader("üí° Comprehensive Recommendations")
    
    for i, rec in enumerate(aggregated_results['comprehensive_recommendations'], 1):
        st.write(f"{i}. {rec}")

# Keeping all existing display functions...
def display_clo_interpretation(clo_results):
    """Display detailed interpretation of CLO analysis results"""
    st.markdown("---")
    st.subheader("üìä ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå CLO")
    
    # Calculate average CLO score
    clo_scores = [data['score'] for data in clo_results.values()]
    avg_clo = sum(clo_scores) / len(clo_scores) if clo_scores else 0
    avg_confidence = sum(data.get('confidence', 0.8) for data in clo_results.values()) / len(clo_results) if clo_results else 0
    
    # Overall CLO interpretation
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        st.markdown("### üìà ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô CLO")
        
        # Score interpretation
        if avg_clo >= 85:
            st.success(f"üåü **‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°** - ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {avg_clo:.1f}%")
            st.write("‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°")
        elif avg_clo >= 70:
            st.success(f"‚úÖ **‡∏î‡∏µ** - ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {avg_clo:.1f}%")
            st.write("‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏î‡∏µ")
        elif avg_clo >= 60:
            st.warning(f"‚ö†Ô∏è **‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á** - ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {avg_clo:.1f}%")
            st.write("‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤")
        else:
            st.error(f"‚ùå **‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏°‡∏≤‡∏Å** - ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {avg_clo:.1f}%")
            st.write("‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠")
    
    with col2:
        st.markdown("### ü§ñ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à AI")
        st.metric("AI Confidence", f"{avg_confidence*100:.0f}%")
        if avg_confidence >= 0.9:
            st.write("‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å")
        elif avg_confidence >= 0.8:
            st.write("‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á")
        else:
            st.write("‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á")
    
    with col3:
        st.markdown("### üìä ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô")
        st.write("üåü 85%+ = ‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°")
        st.write("‚úÖ 70-84% = ‡∏î‡∏µ")
        st.write("‚ö†Ô∏è 60-69% = ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á")
        st.write("‚ùå <60% = ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á")
    
    # Individual CLO interpretation
    st.markdown("### üéØ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏≤‡∏¢‡∏ï‡∏±‡∏ß")
    
    # Create interpretation table
    interpretation_data = []
    for clo_code, clo_data in clo_results.items():
        score = clo_data['score']
        confidence = clo_data.get('confidence', 0.8)
        
        # Determine status
        if score >= 85:
            status = "üåü ‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°"
            recommendation = "‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"
        elif score >= 70:
            status = "‚úÖ ‡∏î‡∏µ"
            recommendation = "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏ì‡∏µ‡∏®‡∏∂‡∏Å‡∏©‡∏≤"
        elif score >= 60:
            status = "‚ö†Ô∏è ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á"
            recommendation = "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"
        else:
            status = "‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á"
            recommendation = "‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö CLO"
        
        interpretation_data.append({
            'CLO': clo_code,
            '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô': f"{score:.1f}%",
            '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞': status,
            '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à AI': f"{confidence*100:.0f}%",
            '‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô': recommendation
        })
    
    interpretation_df = pd.DataFrame(interpretation_data)
    st.dataframe(interpretation_df, use_container_width=True, hide_index=True)

def display_enhanced_clo_analysis(clo_results, key_prefix=""):
    """Display enhanced CLO analysis with AI insights using gauge charts"""
    st.subheader("üìã Course Learning Outcomes (CLO) Analysis")
    
    if not clo_results:
        st.warning("No CLO data available for this course")
        return
    
    # Display CLO Gauge Charts - now 4 CLOs per course
    clo_items = list(clo_results.items())
    
    # Create columns for gauge charts (4 columns for 4 CLOs)
    cols = st.columns(4)
    for j, (clo_code, clo_data) in enumerate(clo_items):
        with cols[j % 4]:
            score = clo_data['score']
            confidence = clo_data.get('confidence', 0.8)
            
            # Create gauge chart
            fig = create_enhanced_gauge_chart(
                score, 
                f"{clo_code} Alignment", 
                confidence if clo_data.get('ai_enhanced') else None
            )
            st.plotly_chart(fig, use_container_width=True, key=f"{key_prefix}_clo_{clo_code}_gauge")
            
            # Status indicator
            if score >= 85:
                st.success(f"üåü Excellent ({score:.1f}%)")
            elif score >= 70:
                st.success(f"‚úÖ Good ({score:.1f}%)")
            elif score >= 60:
                st.warning(f"‚ö†Ô∏è Fair ({score:.1f}%)")
            else:
                st.error(f"‚ùå Poor ({score:.1f}%)")
    
    # Add comprehensive interpretation section
    display_clo_interpretation(clo_results)
    
    # Detailed CLO Analysis with AI insights
    for clo_code, clo_data in clo_results.items():
        with st.expander(f"{clo_code}: {clo_data['description'][:60]}..."):
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.write(f"**Description:** {clo_data['description']}")
                st.write(f"**Keywords Found:** {', '.join(clo_data['found_keywords']) if clo_data['found_keywords'] else 'None'}")
                
                # AI Insights (if available)
                if clo_data.get('ai_insights'):
                    st.write("**ü§ñ AI Insights:**")
                    for insight in clo_data['ai_insights']:
                        st.write(f"‚Ä¢ {insight}")
                
                # Coverage bar
                coverage = clo_data['coverage']
                st.progress(coverage)
                st.caption(f"Keyword Coverage: {coverage*100:.1f}% ({len(clo_data['found_keywords'])}/{clo_data['total_keywords']})")
            
            with col2:
                score = clo_data['score']
                confidence = clo_data.get('confidence', 0.8)
                
                st.metric("Score", f"{score:.1f}%")
                st.metric("Confidence", f"{confidence*100:.0f}%")
                
                if clo_data.get('ai_enhanced'):
                    st.success("ü§ñ AI Enhanced")
                else:
                    st.info("üìä Rule-based")
                
                # Score status
                if score >= 80:
                    st.success("Excellent")
                elif score >= 70:
                    st.info("Good")
                elif score >= 60:
                    st.warning("Fair")
                else:
                    st.error("Needs Improvement")

def display_plo_analysis(plo_results, key_prefix=""):
    """Display Program Learning Outcome analysis with gauge charts"""
    st.subheader("üéØ Program Learning Outcomes (PLO) Analysis")
    
    if not plo_results:
        st.warning("No PLO mapping available for this course")
        return
    
    # Display PLO Gauge Charts
    plo_items = list(plo_results.items())
    
    # Create columns for gauge charts
    cols = st.columns(len(plo_items))
    for i, (plo_code, plo_data) in enumerate(plo_items):
        with cols[i]:
            score = plo_data['score']
            confidence = plo_data.get('confidence', 0.8)
            
            # Create gauge chart
            fig = create_enhanced_gauge_chart(
                score, 
                f"{plo_code}\n{ENHANCED_PLOS[plo_code]['title'][:20]}...",
                confidence
            )
            st.plotly_chart(fig, use_container_width=True, key=f"{key_prefix}_plo_{plo_code}_gauge")
            
            # Status indicator  
            if score >= 85:
                st.success(f"üåü Excellent ({score:.1f}%)")
            elif score >= 70:
                st.success(f"‚úÖ Good ({score:.1f}%)")
            elif score >= 60:
                st.warning(f"‚ö†Ô∏è Fair ({score:.1f}%)")
            else:
                st.error(f"‚ùå Poor ({score:.1f}%)")
    
    st.markdown("---")
    
    # Detailed PLO Analysis
    for plo_code, plo_data in plo_results.items():
        with st.expander(f"{plo_code}: {ENHANCED_PLOS[plo_code]['title']}"):
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.write(f"**Description:** {plo_data['description']}")
                st.write(f"**Related CLOs:** {', '.join(plo_data['related_clos'])}")
            
            with col2:
                score = plo_data['score']
                confidence = plo_data.get('confidence', 0.8)
                st.metric(f"{plo_code} Score", f"{score:.1f}%")
                st.metric("Confidence", f"{confidence*100:.0f}%")

def display_ylo_analysis(ylo_results, key_prefix=""):
    """Display Year Learning Outcome analysis with gauge charts"""
    st.subheader("üìà Year Learning Outcomes (YLO) Analysis")
    
    if not ylo_results:
        st.warning("No YLO mapping available for this course")
        return
    
    # Display YLO Gauge Charts
    ylo_items = list(ylo_results.items())
    
    # Group by Year Level
    year1_ylos = [(code, data) for code, data in ylo_items if data['level'] == 'Year 1']
    year2_ylos = [(code, data) for code, data in ylo_items if data['level'] == 'Year 2']
    
    if year1_ylos:
        st.write("**Year 1 Learning Outcomes:**")
        cols = st.columns(len(year1_ylos))
        for i, (ylo_code, ylo_data) in enumerate(year1_ylos):
            with cols[i]:
                score = ylo_data['score']
                confidence = ylo_data.get('confidence', 0.8)
                
                # Create gauge chart
                fig = create_enhanced_gauge_chart(
                    score, 
                    f"{ylo_code}\n{ylo_data['cognitive_level']}",
                    confidence
                )
                st.plotly_chart(fig, use_container_width=True, key=f"{key_prefix}_ylo_{ylo_code}_gauge")
                
                # Status indicator
                if score >= 85:
                    st.success(f"üåü Excellent ({score:.1f}%)")
                elif score >= 70:
                    st.success(f"‚úÖ Good ({score:.1f}%)")
                elif score >= 60:
                    st.warning(f"‚ö†Ô∏è Fair ({score:.1f}%)")
                else:
                    st.error(f"‚ùå Poor ({score:.1f}%)")
    
    if year2_ylos:
        st.write("**Year 2 Learning Outcomes:**")
        cols = st.columns(len(year2_ylos))
        for i, (ylo_code, ylo_data) in enumerate(year2_ylos):
            with cols[i]:
                score = ylo_data['score']
                confidence = ylo_data.get('confidence', 0.8)
                
                # Create gauge chart
                fig = create_enhanced_gauge_chart(
                    score, 
                    f"{ylo_code}\n{ylo_data['cognitive_level']}",
                    confidence
                )
                st.plotly_chart(fig, use_container_width=True, key=f"{key_prefix}_ylo_{ylo_code}_gauge")
                
                # Status indicator
                if score >= 85:
                    st.success(f"üåü Excellent ({score:.1f}%)")
                elif score >= 70:
                    st.success(f"‚úÖ Good ({score:.1f}%)")
                elif score >= 60:
                    st.warning(f"‚ö†Ô∏è Fair ({score:.1f}%)")
                else:
                    st.error(f"‚ùå Poor ({score:.1f}%)")
    
    st.markdown("---")
    
    # Detailed YLO Analysis
    for ylo_code, ylo_data in ylo_results.items():
        with st.expander(f"{ylo_code}: {ylo_data['level']} - {ylo_data['cognitive_level']}"):
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.write(f"**Description:** {ylo_data['description']}")
                st.write(f"**Related PLOs:** {', '.join(ylo_data['related_plos'])}")
                st.write(f"**Year Level:** {ylo_data['level']}")
                st.write(f"**Cognitive Level:** {ylo_data['cognitive_level']}")
            
            with col2:
                score = ylo_data['score']
                confidence = ylo_data.get('confidence', 0.8)
                st.metric(f"{ylo_code} Score", f"{score:.1f}%")
                st.metric("Confidence", f"{confidence*100:.0f}%")

def display_alignment_matrix(results, key_prefix=""):
    """Display alignment matrix visualization"""
    st.subheader("üîó Learning Outcome Alignment Matrix")
    
    # Add interpretation guide
    with st.expander("üìñ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏ú‡∏ô‡∏†‡∏≤‡∏û‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå"):
        st.write("**‡∏™‡∏µ‡∏Ç‡∏≠‡∏á‡πÇ‡∏´‡∏ô‡∏î:**")
        st.write("‚Ä¢ üî¥ ‡∏™‡∏µ‡πÅ‡∏î‡∏á = CLO (Course Learning Outcomes)")
        st.write("‚Ä¢ üîµ ‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô = PLO (Program Learning Outcomes)")
        st.write("‚Ä¢ üü¢ ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = YLO (Year Learning Outcomes)")
        st.write("")
        st.write("**‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°:**")
        st.write("‚Ä¢ ‡∏¢‡∏¥‡πà‡∏á‡∏´‡∏ô‡∏≤ = ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÅ‡∏ô‡πà‡∏ô‡πÅ‡∏ü‡πâ‡∏ô")
        st.write("‚Ä¢ ‡∏¢‡∏¥‡πà‡∏á‡∏ö‡∏≤‡∏á = ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥/‡∏Ñ‡∏ß‡∏£‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå")
    
    # Sankey Diagram for CLO-PLO-YLO Flow
    st.subheader("üìä Learning Outcome Flow")
    
    # Prepare data for Sankey diagram
    nodes = []
    links = []
    node_colors = []
    
    # Add CLO nodes
    clo_nodes = list(results['clo_results'].keys())
    for clo in clo_nodes:
        nodes.append(f"CLO: {clo}")
        node_colors.append('#FF9999')
    
    # Add PLO nodes
    plo_nodes = list(results['plo_results'].keys())
    for plo in plo_nodes:
        nodes.append(f"PLO: {plo}")
        node_colors.append('#99CCFF')
    
    # Add YLO nodes
    ylo_nodes = list(results['ylo_results'].keys())
    for ylo in ylo_nodes:
        nodes.append(f"YLO: {ylo}")
        node_colors.append('#99FF99')
    
    # Create links
    matrix = results['alignment_matrix']
    
    # CLO to PLO links
    for clo, plos in matrix['clo_to_plo'].items():
        clo_idx = nodes.index(f"CLO: {clo}")
        for plo in plos:
            plo_idx = nodes.index(f"PLO: {plo}")
            links.append({
                'source': clo_idx,
                'target': plo_idx,
                'value': results['clo_results'][clo]['score']
            })
    
    # PLO to YLO links
    for plo, ylos in matrix['plo_to_ylo'].items():
        plo_idx = nodes.index(f"PLO: {plo}")
        for ylo in ylos:
            ylo_idx = nodes.index(f"YLO: {ylo}")
            links.append({
                'source': plo_idx,
                'target': ylo_idx,
                'value': results['plo_results'][plo]['score']
            })
    
    # Create Sankey diagram
    if nodes and links:
        fig = go.Figure(data=[go.Sankey(
            node=dict(
                pad=15,
                thickness=20,
                line=dict(color="black", width=0.5),
                label=nodes,
                color=node_colors
            ),
            link=dict(
                source=[link['source'] for link in links],
                target=[link['target'] for link in links],
                value=[link['value'] for link in links]
            )
        )])
        
        fig.update_layout(
            title_text="Learning Outcome Alignment Flow",
            font_size=12,
            height=500
        )
        st.plotly_chart(fig, use_container_width=True, key=f"{key_prefix}_sankey")
    
    # Enhanced Alignment Summary Table
    st.subheader("üìã Alignment Summary")
    
    alignment_data = []
    for clo_code, clo_data in results['clo_results'].items():
        related_plos = matrix['clo_to_plo'].get(clo_code, [])
        related_ylos = []
        for plo in related_plos:
            related_ylos.extend(matrix['plo_to_ylo'].get(plo, []))
        
        ai_status = "ü§ñ AI" if clo_data.get('ai_enhanced') else "üìä Rule"
        confidence = f"{clo_data.get('confidence', 0.8)*100:.0f}%"
        
        alignment_data.append({
            'CLO': clo_code,
            'Score': f"{clo_data['score']:.1f}%",
            'Confidence': confidence,
            'Analysis': ai_status,
            'Related PLOs': ', '.join(related_plos),
            'Related YLOs': ', '.join(set(related_ylos))
        })
    
    if alignment_data:
        alignment_df = pd.DataFrame(alignment_data)
        st.dataframe(alignment_df, use_container_width=True)

def display_comprehensive_interpretation(results):
    """Display comprehensive interpretation of all assessment results"""
    st.subheader("üìä ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°")
    
    # Overview metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        clo_avg = results['overall_scores']['clo_average']
        st.metric("CLO Average", f"{clo_avg:.1f}%", 
                 f"{clo_avg-70:.1f}%" if clo_avg >= 70 else f"{clo_avg-70:.1f}%")
    
    with col2:
        plo_avg = results['overall_scores']['plo_average']
        st.metric("PLO Average", f"{plo_avg:.1f}%",
                 f"{plo_avg-70:.1f}%" if plo_avg >= 70 else f"{plo_avg-70:.1f}%")
    
    with col3:
        ylo_avg = results['overall_scores']['ylo_average']
        st.metric("YLO Average", f"{ylo_avg:.1f}%",
                 f"{ylo_avg-70:.1f}%" if ylo_avg >= 70 else f"{ylo_avg-70:.1f}%")
    
    with col4:
        confidence = results['overall_scores'].get('overall_confidence', 0.8)
        st.metric("AI Confidence", f"{confidence*100:.0f}%")
    
    st.markdown("---")
    
    # Detailed interpretation
    st.markdown("### üéØ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå CLO ‚Üí PLO ‚Üí YLO")
    
    # Create interpretation table
    interpretation_data = []
    
    for clo_code, clo_data in results['clo_results'].items():
        # Get related PLOs and YLOs
        related_plos = results['alignment_matrix']['clo_to_plo'].get(clo_code, [])
        related_ylos = []
        for plo in related_plos:
            related_ylos.extend(results['alignment_matrix']['plo_to_ylo'].get(plo, []))
        
        interpretation_data.append({
            'CLO': clo_code,
            '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô': f"{clo_data['score']:.1f}%",
            '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à': f"{clo_data.get('confidence', 0.8)*100:.0f}%",
            '‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå': "ü§ñ AI" if clo_data.get('ai_enhanced') else "üìä Rule",
            'PLO ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á': ', '.join(related_plos),
            'YLO ‡∏ó‡∏µ‡πà‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô': ', '.join(set(related_ylos))
        })
    
    interpretation_df = pd.DataFrame(interpretation_data)
    st.dataframe(interpretation_df, use_container_width=True, hide_index=True)
    
    # Generate comprehensive recommendations
    st.markdown("### üí° ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å")
    
    recommendations = []
    
    # CLO-based recommendations
    low_clos = [clo for clo, data in results['clo_results'].items() if data['score'] < 70]
    if low_clos:
        recommendations.append({
            '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó': 'CLO',
            '‡∏õ‡∏±‡∏ç‡∏´‡∏≤': f"CLO ‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå: {', '.join(low_clos)}",
            '‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç': '‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå'
        })
    
    # PLO coverage recommendations
    missing_plos = [plo for plo in ['PLO1', 'PLO2', 'PLO3'] if plo not in results['plo_results']]
    if missing_plos:
        plo_descriptions = {
            'PLO1': '‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°',
            'PLO2': '‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£',
            'PLO3': '‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≠‡∏î'
        }
        for plo in missing_plos:
            recommendations.append({
                '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó': 'PLO',
                '‡∏õ‡∏±‡∏ç‡∏´‡∏≤': f"‡∏Ç‡∏≤‡∏î {plo}: {plo_descriptions[plo]}",
                '‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç': f'‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏î‡πâ‡∏≤‡∏ô{plo_descriptions[plo]}'
            })
    
    if recommendations:
        rec_df = pd.DataFrame(recommendations)
        st.dataframe(rec_df, use_container_width=True, hide_index=True)
    else:
        st.success("‚úÖ ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏î‡∏∏‡∏•‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏î‡∏µ‡πÅ‡∏•‡πâ‡∏ß")

# Helper Functions
def generate_improvement_recommendations(results):
    """Generate specific improvement recommendations in Thai"""
    recommendations = []
    
    # CLO-based recommendations
    clo_scores = [data['score'] for data in results['clo_results'].values()]
    if clo_scores:
        avg_clo = sum(clo_scores) / len(clo_scores)
        if avg_clo < 70:
            recommendations.append("‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤ (CLO) ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô")
        elif avg_clo < 80:
            recommendations.append("‡πÄ‡∏™‡∏£‡∏¥‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö CLO ‡πÉ‡∏´‡πâ‡∏ñ‡∏∂‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°")
    
    # PLO-based recommendations
    plo_scores = [data['score'] for data in results['plo_results'].values()]
    if plo_scores:
        avg_plo = sum(plo_scores) / len(plo_scores)
        if avg_plo < 70:
            recommendations.append("‡πÄ‡∏™‡∏£‡∏¥‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£ (PLO) ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô")
        elif avg_plo < 85:
            recommendations.append("‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏•‡∏∞ PLO ‡πÉ‡∏´‡πâ‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô")
    
    # YLO-based recommendations
    ylo_scores = [data['score'] for data in results['ylo_results'].values()]
    if ylo_scores:
        avg_ylo = sum(ylo_scores) / len(ylo_scores)
        if avg_ylo < 70:
            recommendations.append("‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ (YLO)")
        elif avg_ylo < 85:
            recommendations.append("‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á")
    
    # Specific content recommendations based on CLO scores
    low_clos = [clo for clo, data in results['clo_results'].items() if data['score'] < 70]
    if low_clos:
        recommendations.append(f"‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö {', '.join(low_clos)}")
    
    # Enhanced recommendations with Assessment ID
    assessment_id = results.get('assessment_id', 'Unknown')
    if assessment_id != 'Unknown':
        recommendations.append(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ Assessment ID: {assessment_id}")
    
    # AI-specific recommendations
    if results.get('ai_enhanced'):
        low_confidence_clos = [clo for clo, data in results['clo_results'].items() if data.get('confidence', 1) < 0.8]
        if low_confidence_clos:
            recommendations.append(f"‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô {', '.join(low_confidence_clos)}")
        
        # High-level AI recommendations
        overall_confidence = results['overall_scores'].get('overall_confidence', 0)
        if overall_confidence > 0.95:
            recommendations.append("‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏£‡∏ì‡∏µ‡∏®‡∏∂‡∏Å‡∏©‡∏≤")
        elif overall_confidence > 0.90:
            recommendations.append("‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏î‡∏µ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á")
    
    # Course-specific recommendations
    course_code = results.get('course_code', '')
    if '282712' in course_code:  # Water resource course
        recommendations.append("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏ì‡∏µ‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ô‡πâ‡∏≥‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡πÄ‡∏ã‡∏µ‡∏¢‡∏ô")
    elif '282714' in course_code:  # Research methodology
        recommendations.append("‡πÄ‡∏™‡∏£‡∏¥‡∏°‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•")
    elif '282734' in course_code:  # Communication
        recommendations.append("‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏™‡∏∑‡πà‡∏≠‡∏ú‡∏™‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•")
    
    # General enhancement recommendations
    if not recommendations:
        recommendations.append("‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡∏Ñ‡∏ß‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏ô‡∏≥‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á")
        recommendations.append("‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å")
    
    return recommendations[:6]  # Limit to top 6 recommendations

# NEW: Enhanced file upload interface for multiple files
def show_multiple_file_upload_interface():
    """Enhanced file upload interface with multiple file support and AI analysis"""
    st.subheader("üìÅ Multiple File Upload & Aggregated Analysis")
    
    # File upload - now accepts multiple files
    uploaded_files = st.file_uploader(
        "Choose your slide files (you can select multiple files)",
        type=['pdf', 'pptx', 'ppt', 'txt'],
        accept_multiple_files=True,
        help="Upload multiple files from the same course for comprehensive analysis"
    )
    
    # AI Analysis option
    col1, col2, col3 = st.columns([2, 2, 1])
    
    with col1:
        use_ai = st.checkbox(
            "ü§ñ Enable AI Analysis",
            value=False,
            help="Use AI to enhance content analysis (requires API key)",
            key="multi_ai_checkbox"
        )
    
    with col2:
        if use_ai:
            selected_model = st.selectbox(
                "AI Model:",
                options=list(OPENAI_MODELS.keys()),
                format_func=lambda x: OPENAI_MODELS[x],
                index=0,
                help="Select the OpenAI model to use",
                key="multi_model_selector"
            )
        else:
            selected_model = DEFAULT_MODEL
    
    with col3:
        ai_available = check_ai_availability()
        if ai_available:
            st.success("AI Ready")
        else:
            st.info("Demo Mode")
    
    if uploaded_files:
        # File information
        st.write(f"### üìÑ {len(uploaded_files)} Files Selected")
        
        # Show file details
        file_details = []
        total_size = 0
        for file in uploaded_files:
            file_size = len(file.getvalue()) / (1024 * 1024)
            total_size += file_size
            file_details.append({
                'File Name': file.name,
                'Size (MB)': f"{file_size:.1f}",
                'Type': file.type.split('/')[-1].upper()
            })
        
        # Display file details in a table
        file_df = pd.DataFrame(file_details)
        st.dataframe(file_df, use_container_width=True, hide_index=True)
        
        # Summary metrics
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total Files", len(uploaded_files))
        with col2:
            st.metric("Total Size", f"{total_size:.1f} MB")
        with col3:
            st.metric("Analysis Mode", "AI Enhanced" if use_ai else "Rule-based")
        
        # Process files button
        if st.button("üîç Analyze All Files", type="primary", use_container_width=True):
            with st.spinner(f"Processing {len(uploaded_files)} files..."):
                # Progress tracking
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Store individual assessments
                file_assessments = []
                engine = MultiLevelAssessmentEngine()
                
                # Process each file
                for i, uploaded_file in enumerate(uploaded_files):
                    # Update progress
                    progress = (i + 1) / len(uploaded_files)
                    progress_bar.progress(progress)
                    status_text.text(f"Processing file {i+1}/{len(uploaded_files)}: {uploaded_file.name}")
                    
                    # Extract content
                    content = extract_text_from_file(uploaded_file)
                    
                    # AI Analysis (if enabled)
                    ai_analysis = None
                    if use_ai:
                        content_hash = hashlib.md5(content.encode()).hexdigest()
                        ai_analysis = generate_ai_analysis(content_hash, st.session_state.selected_course_code, use_ai, selected_model)
                        # Check if AI analysis actually succeeded
                        if ai_analysis and not ai_analysis.get('ai_generated', False):
                            ai_analysis = None  # Reset to None if it was mock analysis
                    
                    # Multi-level analysis
                    results = engine.calculate_multi_level_alignment(
                        content, 
                        st.session_state.selected_course_code, 
                        ai_analysis
                    )
                    
                    # Add file name to results
                    results['file_name'] = uploaded_file.name
                    file_assessments.append(results)
                
                # Clear progress indicators
                progress_bar.empty()
                status_text.empty()
                
                # Store results in session state
                st.session_state.file_assessments = file_assessments
                st.session_state.analysis_mode = 'multiple'
                
                # Aggregate results
                aggregator = MultiFileAggregator()
                aggregated_results = aggregator.aggregate_assessments(file_assessments)
                st.session_state.aggregated_results = aggregated_results
                
                st.success(f"‚úÖ Successfully analyzed {len(uploaded_files)} files!")
                
                # Add note about AI analysis status
                if use_ai:
                    # Check how many files actually used AI
                    ai_success_count = sum(1 for f in file_assessments if f.get('ai_enhanced', False))
                    if ai_success_count == 0:
                        st.warning("‚ö†Ô∏è AI analysis failed for all files due to API quota. Using rule-based analysis instead.")
                    elif ai_success_count < len(file_assessments):
                        st.info(f"‚ÑπÔ∏è AI analysis successful for {ai_success_count}/{len(file_assessments)} files. Others used rule-based analysis.")
                    else:
                        st.success(f"ü§ñ AI analysis successful for all {len(file_assessments)} files!")
                
                # Show quick summary
                st.markdown("### üìä Quick Summary")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    completeness = aggregated_results['completeness_analysis']['overall_completeness']
                    st.metric("Overall Completeness", f"{completeness:.1f}%")
                
                with col2:
                    improvement = aggregated_results['improvement_metrics']['overall_improvement']
                    st.metric("Avg Improvement", f"+{improvement:.1f}%")
                
                with col3:
                    clo_coverage = aggregated_results['coverage_analysis']['overall_clo_coverage']
                    st.metric("CLO Coverage", f"{clo_coverage:.1f}%")
                
                with col4:
                    plo_coverage = aggregated_results['coverage_analysis']['overall_plo_coverage']
                    st.metric("PLO Coverage", f"{plo_coverage:.1f}%")
                
                return file_assessments, aggregated_results
    
    # Return results from session state if available
    file_assessments = st.session_state.get('file_assessments', None)
    aggregated_results = st.session_state.get('aggregated_results', None)
    
    # Only return if they belong to multiple analysis mode
    if st.session_state.get('analysis_mode') == 'multiple':
        return file_assessments, aggregated_results
    
    return None, None

# Main Application
def main():
    st.set_page_config(
        page_title="Multi-File Assessment System",
        page_icon="üí†",
        layout="wide"
    )
    
    # Initialize session state
    if 'selected_course_code' not in st.session_state:
        st.session_state.selected_course_code = '282712'
    if 'assessor_name' not in st.session_state:
        st.session_state.assessor_name = ''
    
    # Enhanced header
    st.markdown("""
    <style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .info-card {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        margin-bottom: 1rem;
        border-left: 4px solid #667eea;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    </style>
    
    <div class="main-header">
        <h1> Multi-Learning Output Assessment System</h1>
        <p style="font-size: 1.1em;">‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏ö‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö CLO ‚Üí PLO ‚Üí YLO</p>

    </div>
    """, unsafe_allow_html=True)
    
    # Enhanced tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üéØ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô", 
        "üìÅ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå",
        "üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå",
        "üìö ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£", 
        "üìñ ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"
    ])
    
    with tab1:
        # User Information
        st.markdown('<div class="info-card">', unsafe_allow_html=True)
        col1, col2 = st.columns(2)
        with col1:
            st.session_state.assessor_name = st.text_input(
                "üë§ ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô:",
                value=st.session_state.assessor_name,
                placeholder="‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö)"
            )
        with col2:
            # Show current time
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            st.info(f"‚è∞ ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: {current_time}")
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Course Selection
        st.markdown('<div class="info-card">', unsafe_allow_html=True)
        st.subheader("üìö ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô")
        
        course_options = {}
        for code, data in COURSE_DESCRIPTIONS.items():
            course_options[f"{code} - {data['name']}"] = code
        
        selected_course_display = st.selectbox(
            "‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤:",
            options=list(course_options.keys()),
            index=list(course_options.values()).index(st.session_state.selected_course_code)
        )
        
        st.session_state.selected_course_code = course_options[selected_course_display]
        
        # Display course information
        course_info = COURSE_DESCRIPTIONS[st.session_state.selected_course_code]
        
        col1, col2 = st.columns([3, 1])
        with col1:
            st.write(f"**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤:** {course_info['description']}")
        with col2:
            st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô CLOs", len(course_info['clo']))
            st.write(f"PLOs: {', '.join(course_info['plo_mapping'])}")
        
        with st.expander("üìã ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î CLOs ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"):
            for clo_code, clo_desc in course_info['clo'].items():
                st.write(f"**{clo_code}:** {clo_desc}")
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Input Method Selection
        st.markdown("---")
        st.subheader("üìù ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        input_method = st.radio(
            "‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£:",
            ["üìÅ ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß", "‚úèÔ∏è ‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á"],
            horizontal=True
        )
        
        results = None
        content = None
        
        if input_method == "üìÅ ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß":
            # Single file upload interface
            st.markdown('<div class="info-card">', unsafe_allow_html=True)
            st.subheader("üìÅ Single File Upload & Analysis")
            
            uploaded_file = st.file_uploader(
                "Choose your slide file",
                type=['pdf', 'pptx', 'ppt', 'txt'],
                help="Supported formats: PDF, PowerPoint, Text files"
            )
            
            # AI Analysis option
            col1, col2, col3 = st.columns([2, 2, 1])
            with col1:
                use_ai = st.checkbox(
                    "ü§ñ Enable AI Analysis",
                    value=False,
                    help="Use AI to enhance content analysis"
                )
            with col2:
                if use_ai:
                    selected_model = st.selectbox(
                        "AI Model:",
                        options=list(OPENAI_MODELS.keys()),
                        format_func=lambda x: OPENAI_MODELS[x],
                        index=0,
                        help="Select the OpenAI model to use"
                    )
                else:
                    selected_model = DEFAULT_MODEL
            with col3:
                ai_available = check_ai_availability()
                if ai_available:
                    st.success("AI Ready")
                else:
                    st.info("Demo Mode")
            
            if uploaded_file is not None:
                # File information
                file_size = len(uploaded_file.getvalue()) / (1024 * 1024)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("File Name", uploaded_file.name)
                with col2:
                    st.metric("File Size", f"{file_size:.1f} MB")
                with col3:
                    st.metric("File Type", uploaded_file.type.split('/')[-1].upper())
                
                # Process file button
                if st.button("üîç Process File", type="primary", use_container_width=True):
                    with st.spinner("Processing file..."):
                        # Progress tracking
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        # Step 1: Extract content
                        status_text.text("üìÑ Extracting content from file...")
                        progress_bar.progress(25)
                        time.sleep(0.5)
                        
                        content = extract_text_from_file(uploaded_file)
                        
                        # Step 2: AI Analysis (if enabled)
                        ai_analysis = None
                        if use_ai:
                            status_text.text("ü§ñ Performing AI analysis...")
                            progress_bar.progress(50)
                            time.sleep(1)
                            
                            content_hash = hashlib.md5(content.encode()).hexdigest()
                            ai_analysis = generate_ai_analysis(content_hash, st.session_state.selected_course_code, use_ai, selected_model)
                            # Check if AI analysis actually succeeded
                            if ai_analysis and not ai_analysis.get('ai_generated', False):
                                ai_analysis = None  # Reset to None if it was mock analysis
                        
                        # Step 3: Multi-level analysis
                        status_text.text("üéØ Performing multi-level assessment...")
                        progress_bar.progress(75)
                        time.sleep(0.5)
                        
                        engine = MultiLevelAssessmentEngine()
                        results = engine.calculate_multi_level_alignment(
                            content, 
                            st.session_state.selected_course_code, 
                            ai_analysis
                        )
                        
                        # Step 4: Complete
                        status_text.text("‚úÖ Analysis complete!")
                        progress_bar.progress(100)
                        time.sleep(0.5)
                        
                        # Clear progress indicators
                        progress_bar.empty()
                        status_text.empty()
                        
                        # Store results in session state
                        st.session_state.analysis_results = results
                        st.session_state.slide_content = content
                        st.session_state.analysis_mode = 'single'
                        
                        # Show success message
                        if ai_analysis is not None:
                            st.success(f"‚úÖ File processed with AI analysis! Assessment ID: {results.get('assessment_id', 'Unknown')}")
                        else:
                            st.success(f"‚úÖ File processed with rule-based analysis! Assessment ID: {results.get('assessment_id', 'Unknown')}")
            
            st.markdown('</div>', unsafe_allow_html=True)
            
        else:
            # Direct text input
            st.markdown('<div class="info-card">', unsafe_allow_html=True)
            st.subheader("üìù ‡∏õ‡πâ‡∏≠‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
            
            sample_content = f"""
# ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 1: ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô

## ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ
- ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥‡πÉ‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ GIS ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≥
- ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ô‡πâ‡∏≥‡πÅ‡∏ö‡∏ö‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô

## ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô

### 1. ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥
‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö 
‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏Å‡∏Ç‡∏≠‡∏á‡∏ù‡∏ô‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á

### 2. ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ GIS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ô‡πâ‡∏≥
- ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®‡∏†‡∏π‡∏°‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏∏‡πà‡∏°‡∏ô‡πâ‡∏≥
- ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏´‡∏•‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥
- ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ô‡πâ‡∏≥‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ Remote Sensing

### 3. ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô
‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ô‡πâ‡∏≥‡∏ó‡∏µ‡πà‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:
- ‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
- ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
- ‡∏Å‡∏≤‡∏£‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤
            """
            
            content = st.text_area(
                "üìÑ ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:",
                value=sample_content,
                height=400,
                help="‡∏ß‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"
            )
            
            # AI Analysis option for text input
            col1, col2, col3 = st.columns([2, 2, 1])
            with col1:
                use_ai = st.checkbox(
                    "ü§ñ ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ AI",
                    value=False,
                    help="‡πÉ‡∏ä‡πâ AI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤",
                    key="text_ai_checkbox"
                )
            with col2:
                if use_ai:
                    selected_model = st.selectbox(
                        "AI Model:",
                        options=list(OPENAI_MODELS.keys()),
                        format_func=lambda x: OPENAI_MODELS[x],
                        index=0,
                        help="Select the OpenAI model to use",
                        key="text_model_selector"
                    )
                else:
                    selected_model = DEFAULT_MODEL
            with col3:
                # Show content hash preview
                if content.strip():
                    content_hash = hashlib.md5(content.encode()).hexdigest()
                    st.info(f"üîí Hash: `{content_hash[:8]}...`")
            
            st.markdown('</div>', unsafe_allow_html=True)
            
            # Analysis Button
            if st.button("üîç ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå", type="primary", use_container_width=True):
                if content.strip():
                    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• CLO-PLO-YLO..."):
                        # Progress tracking
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        # Step 1: Generate unique ID
                        status_text.text("üÜî Generating unique assessment ID...")
                        progress_bar.progress(15)
                        time.sleep(0.3)
                        
                        # Step 2: AI Analysis (if enabled)
                        ai_analysis = None
                        if use_ai:
                            status_text.text("ü§ñ Performing AI analysis...")
                            progress_bar.progress(35)
                            time.sleep(0.5)
                            
                            content_hash = hashlib.md5(content.encode()).hexdigest()
                            ai_analysis = generate_ai_analysis(content_hash, st.session_state.selected_course_code, use_ai, selected_model)
                            # Check if AI analysis actually succeeded
                            if ai_analysis and not ai_analysis.get('ai_generated', False):
                                ai_analysis = None  # Reset to None if it was mock analysis
                        
                        # Step 3: Multi-level analysis
                        status_text.text("üéØ Performing multi-level assessment...")
                        progress_bar.progress(60)
                        time.sleep(0.5)
                        
                        # Initialize assessment engine
                        engine = MultiLevelAssessmentEngine()
                        
                        # Perform multi-level analysis
                        results = engine.calculate_multi_level_alignment(
                            content, 
                            st.session_state.selected_course_code, 
                            ai_analysis
                        )
                        
                        # Step 4: Complete
                        status_text.text("‚úÖ Analysis complete!")
                        progress_bar.progress(100)
                        time.sleep(0.5)
                        
                        # Clear progress indicators
                        progress_bar.empty()
                        status_text.empty()
                        
                        # Store results in session state
                        st.session_state.analysis_results = results
                        st.session_state.slide_content = content
                        st.session_state.analysis_mode = 'single'
                        
                        # Show success message with unique ID
                        assessment_id = results.get('assessment_id', 'Unknown')
                        if ai_analysis is not None:
                            st.success(f"‚úÖ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ AI ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! Assessment ID: `{assessment_id}`")
                        else:
                            st.success(f"‚úÖ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ö‡∏ö Rule-based ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! Assessment ID: `{assessment_id}`")
                        
                        # Show content hash
                        content_hash = results.get('content_hash', '')
                        if content_hash:
                            st.info(f"üîí Content Hash: `{content_hash}`")
                else:
                    st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡πâ‡∏≠‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
        
        # Display results if available
        if results:
            st.markdown("---")
            create_multi_level_dashboard(results, key_prefix="single_tab1")
            
            # Recommendations
            st.markdown("---")
            st.markdown('<div class="info-card">', unsafe_allow_html=True)
            st.subheader("üí° ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á")
            
            recommendations = generate_improvement_recommendations(results)
            for i, rec in enumerate(recommendations, 1):
                st.write(f"{i}. {rec}")
            
            # Show tracking info
            assessment_id = results.get('assessment_id', 'Unknown')
            content_hash = results.get('content_hash', '')
            st.markdown(f"**üÜî Tracking Info:** Assessment ID: `{assessment_id}` | Content Hash: `{content_hash[:16]}...`")
            st.markdown('</div>', unsafe_allow_html=True)
    
    with tab2:
        # Multiple file upload interface
        try:
            file_assessments, aggregated_results = show_multiple_file_upload_interface()
            
            # Display aggregated results if available
            if aggregated_results is not None:
                st.markdown("---")
                # Use a container to isolate the dashboard
                with st.container():
                    create_multi_file_dashboard(aggregated_results, key_prefix="tab2")
        except Exception as e:
            st.error(f"Error in multi-file analysis: {str(e)}")
            st.exception(e)
    
    with tab3:
        # Display analysis results
        if hasattr(st.session_state, 'analysis_mode'):
            if st.session_state.analysis_mode == 'single' and hasattr(st.session_state, 'analysis_results'):
                st.subheader("üìä Single File Analysis Results")
                create_multi_level_dashboard(st.session_state.analysis_results, key_prefix="tab3_single")
            elif st.session_state.analysis_mode == 'multiple' and hasattr(st.session_state, 'aggregated_results'):
                st.subheader("üìä Multi-File Aggregated Results")
                create_multi_file_dashboard(st.session_state.aggregated_results, key_prefix="tab3")
                
                # Option to view individual file results
                if hasattr(st.session_state, 'file_assessments'):
                    st.markdown("---")
                    st.subheader("üìÑ Individual File Results")
                    
                    file_names = [f['file_name'] for f in st.session_state.file_assessments]
                    selected_file = st.selectbox("Select file to view details:", file_names)
                    
                    # Find and display selected file results
                    for i, assessment in enumerate(st.session_state.file_assessments):
                        if assessment['file_name'] == selected_file:
                            create_multi_level_dashboard(assessment, key_prefix=f"tab3_multi_{i}")
                            break
        else:
            st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö '‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå'")
    
    with tab4:
        # Program Overview Section
        st.markdown('<div class="info-card">', unsafe_allow_html=True)
        st.markdown(f"### {PROGRAM_OVERVIEW['program_name']}")
        
        st.markdown("#### ‡∏õ‡∏£‡∏±‡∏ä‡∏ç‡∏≤‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£")
        st.write(PROGRAM_OVERVIEW['program_philosophy'])
        
        st.markdown("#### ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£")
        for i, obj in enumerate(PROGRAM_OVERVIEW['program_objectives'], 1):
            st.write(f"{i}. {obj}")
        
        st.markdown("#### ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏≠‡∏≤‡∏ä‡∏µ‡∏û")
        for career in PROGRAM_OVERVIEW['career_prospects']:
            st.write(f"‚Ä¢ {career}")
        st.markdown('</div>', unsafe_allow_html=True)
    
    with tab5:
        # User manual
        st.markdown('<div class="info-card">', unsafe_allow_html=True)
        st.subheader("üìñ ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏ö Multi-File Assessment")
        
        st.markdown("""
        ### üÜï ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà: ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå
        
        **‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå:**
        - üìä **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô**: ‡∏î‡∏π‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° CLO/PLO/YLO ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå
        - üìà **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á**: ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£
        - üéØ **‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á-‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô**: ‡∏£‡∏∞‡∏ö‡∏∏ CLO ‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏™‡∏£‡∏¥‡∏°
        - üí° **‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ß‡∏°**: ‡πÑ‡∏î‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£
        
        ### ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
        
        #### 1. ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß
        - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤
        - ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
        - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ AI ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        - ‡∏Å‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        
        #### 2. ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå
        - ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πá‡∏ö "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå"
        - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        - ‡∏Å‡∏î "Analyze All Files"
        - ‡∏î‡∏π‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏ß‡∏°
        
        #### 3. ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏ú‡∏•‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏ß‡∏°
        - **Overall Completeness**: % ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á Learning Outcomes
        - **Average Improvement**: ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå
        - **Coverage**: % ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞ CLO
        - **Missing Outcomes**: CLO/PLO/YLO ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡∏Ç‡∏≤‡∏î‡∏≠‡∏¢‡∏π‡πà
        
        ### ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
        - üåü 85%+ = ‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°
        - ‚úÖ 70-84% = ‡∏î‡∏µ
        - ‚ö†Ô∏è 60-69% = ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        - ‚ùå <60% = ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        
        ### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
        
        **‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå**: ‡∏°‡∏µ‡∏™‡πÑ‡∏•‡∏î‡πå 4 ‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤ 282712
        - ‡πÑ‡∏ü‡∏•‡πå 1: ‡∏ö‡∏ó‡∏ô‡∏≥ (CLO1: 75%, CLO2: 60%)
        - ‡πÑ‡∏ü‡∏•‡πå 2: ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ GIS (CLO3: 85%)
        - ‡πÑ‡∏ü‡∏•‡πå 3: ‡∏Å‡∏£‡∏ì‡∏µ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ (CLO4: 80%)
        - ‡πÑ‡∏ü‡∏•‡πå 4: ‡∏™‡∏£‡∏∏‡∏õ (CLO1: 70%, CLO2: 75%)
        
        **‡∏ú‡∏•‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏ß‡∏°**:
        - CLO1: ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 72.5% (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏à‡∏≤‡∏Å 75% ‡πÄ‡∏õ‡πá‡∏ô 75%)
        - CLO2: ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 67.5% (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏à‡∏≤‡∏Å 60% ‡πÄ‡∏õ‡πá‡∏ô 75%)
        - CLO3: ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 85% (‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô)
        - CLO4: ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 80% (‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô)
        - **Overall Completeness**: 100% (‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å CLO)
        - **Improvement**: +15% ‡πÉ‡∏ô CLO2
        
        ### ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
        1. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á**: ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        2. **‡πÑ‡∏ü‡∏•‡πå 3-5 ‡πÑ‡∏ü‡∏•‡πå**: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        3. **‡∏î‡∏π Missing Outcomes**: ‡πÄ‡∏ô‡πâ‡∏ô‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î
        4. **‡πÉ‡∏ä‡πâ AI ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥**: AI ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å
        
        ### ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
        
        **‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î
        **‡πÅ‡∏Å‡πâ:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 200MB) ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå
        
        **‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏ú‡∏•‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡πà‡∏≥
        **‡πÅ‡∏Å‡πâ:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö CLO ‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤
        
        **‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** AI ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        **‡πÅ‡∏Å‡πâ:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API key ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ Rule-based ‡πÅ‡∏ó‡∏ô
        """)
        
        # System information
        st.markdown("---")
        st.markdown("### ‚ÑπÔ∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏ö‡∏ö")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown("**üîß ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô**")
            st.write("‚Ä¢ v2.0 Multi-File")
            st.write("‚Ä¢ Fixed OpenAI Model")
        
        with col2:
            st.markdown("**üìä ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥**")
            st.write("‚Ä¢ 4 CLOs ‡∏ï‡πà‡∏≠‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤")
            st.write("‚Ä¢ Multi-file Analysis")
            st.write("‚Ä¢ Aggregated Results")
        
        with col3:
            st.markdown("**üéØ ‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤**")
            st.write(f"‚Ä¢ {len(COURSE_DESCRIPTIONS)} ‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤")
            st.write("‚Ä¢ 3 PLOs")
            st.write("‚Ä¢ 7 YLOs")
        
        with col4:
            st.markdown("**üÜï ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà**")
            st.write("‚Ä¢ Multiple Files")
            st.write("‚Ä¢ Completeness Analysis")
            st.write("‚Ä¢ Improvement Metrics")
        
        st.markdown('</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()
